default:
  default:
    basic:
      max_time: 60.0
      max_num_retries: 6

    batch:
      poll_interval: 300.0
      max_tokens_per_day: null
      max_num_retries: 0

    concurrent:
      max_requests_per_minute: null
      max_tokens_per_minute: null
      max_num_retries: 3

huggingface:
  text-embeddings-inference:
    batch:
      max_tokens_per_day: null

openai:
  text-embedding-3-large:
    batch:
      max_tokens_per_day: 20_000_000.0

    concurrent:
      max_requests_per_minute: 5_000.0
      max_tokens_per_minute: 1_000_000.0

  text-embedding-3-small:
    batch:
      max_tokens_per_day: 20_000_000.0

    concurrent:
      max_requests_per_minute: 5_000.0
      max_tokens_per_minute: 1_000_000.0

  text-embedding-ada-002:
    batch:
      max_tokens_per_day: 20_000_000.0

    concurrent:
      max_requests_per_minute: 5_000.0
      max_tokens_per_minute: 1_000_000.0
