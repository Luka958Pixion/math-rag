default:
  default:
    basic:
      max_time: 60.0
      max_num_retries: 6

    batch:
      poll_interval: 300.0
      max_tokens_per_day: null
      max_input_file_size: 104857600  # 100 * 1024 * 1024 (100MB)
      max_num_retries: 0

    concurrent:
      max_requests_per_minute: null
      max_tokens_per_minute: null
      max_num_retries: 3

huggingface:
  text-generation-inference:
    batch:
      max_tokens_per_day: null

openai:
  gpt-4o-mini:
    batch:
      max_tokens_per_day: 20000000.0

    concurrent:
      max_requests_per_minute: 5000.0
      max_tokens_per_minute: 2000000.0

  gpt-4.1-mini:
    batch:
      max_tokens_per_day: 20000000.0

    concurrent:
      max_requests_per_minute: 5000.0
      max_tokens_per_minute: 2000000.0

  gpt-4.1-nano:
    batch:
      max_tokens_per_day: 20000000.0

    concurrent:
      max_requests_per_minute: 5000.0
      max_tokens_per_minute: 2000000.0

  gpt-4.1:
    batch:
      max_tokens_per_day: 1350000.0

    concurrent:
      max_requests_per_minute: 5000.0
      max_tokens_per_minute: 450000.0
