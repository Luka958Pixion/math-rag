default:
  default:
    basic:
      max_time: 60.0
      max_num_retries: 6

    batch:
      poll_interval: 300.0
      max_tokens_per_day: null
      max_num_retries: 0

    concurrent:
      max_requests_per_minute: null
      max_tokens_per_minute: null
      max_num_retries: 3

huggingface:
  text-generation-inference:
    batch:
      max_tokens_per_day: null

openai:
  gpt-4o-mini:
    batch:
      max_tokens_per_day: 20_000_000.0

    concurrent:
      max_requests_per_minute: 5_000.0
      max_tokens_per_minute: 2_000_000.0

  gpt-4.1-mini:
    batch:
      max_tokens_per_day: 20_000_000.0

    concurrent:
      max_requests_per_minute: 5_000.0
      max_tokens_per_minute: 2_000_000.0

  gpt-4.1-nano:
    batch:
      max_tokens_per_day: 20_000_000.0

    concurrent:
      max_requests_per_minute: 5_000.0
      max_tokens_per_minute: 2_000_000.0

  gpt-4.1:
    batch:
      max_tokens_per_day: 1_350_000.0

    concurrent:
      max_requests_per_minute: 5_000.0
      max_tokens_per_minute: 450_000.0
