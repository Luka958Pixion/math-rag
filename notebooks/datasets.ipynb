{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "import tarfile\n",
    "\n",
    "\n",
    "ARTICLES_PATH = '../tmp/articles'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15043/154124979.py:39: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall(path=dest_folder)\n"
     ]
    }
   ],
   "source": [
    "def get_gzip_original_filename(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        if f.read(2) != b'\\x1f\\x8b':\n",
    "            return None\n",
    "        f.read(1)\n",
    "        flag = f.read(1)[0]\n",
    "        f.read(4)\n",
    "        f.read(1)\n",
    "        f.read(1)\n",
    "        orig_name = None\n",
    "        if flag & 0x08:\n",
    "            name_bytes = bytearray()\n",
    "            while True:\n",
    "                b = f.read(1)\n",
    "                if not b or b == b'\\x00':\n",
    "                    break\n",
    "                name_bytes.extend(b)\n",
    "            try:\n",
    "                orig_name = name_bytes.decode('utf-8')\n",
    "            except UnicodeDecodeError:\n",
    "                orig_name = name_bytes.decode('latin1')\n",
    "        return orig_name\n",
    "\n",
    "\n",
    "def extract_gz(file_path, dest_folder):\n",
    "    orig_name = get_gzip_original_filename(file_path)\n",
    "    if not orig_name:\n",
    "        orig_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    dest_path = os.path.join(dest_folder, orig_name)\n",
    "    with gzip.open(file_path, 'rb') as f_in, open(dest_path, 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "\n",
    "def extract_tar_gz(file_path, dest_folder):\n",
    "    with tarfile.open(file_path, 'r:gz') as tar:\n",
    "        tar.extractall(path=dest_folder)\n",
    "\n",
    "\n",
    "def process_subdir(subdir_path):\n",
    "    files = os.listdir(subdir_path)\n",
    "    pdf_files = {f for f in files if f.endswith('.pdf')}\n",
    "    for pdf in pdf_files:\n",
    "        base_name = pdf[:-4]\n",
    "        gz_name = f'arXiv-{base_name}.gz'\n",
    "        tar_gz_name = f'arXiv-{base_name}.tar.gz'\n",
    "        gz_file = None\n",
    "        if tar_gz_name in files:\n",
    "            gz_file = tar_gz_name\n",
    "        elif gz_name in files:\n",
    "            gz_file = gz_name\n",
    "        if gz_file:\n",
    "            new_dir = os.path.join(subdir_path, base_name)\n",
    "            os.makedirs(new_dir, exist_ok=True)\n",
    "            shutil.move(os.path.join(subdir_path, pdf), new_dir)\n",
    "            shutil.move(os.path.join(subdir_path, gz_file), new_dir)\n",
    "            new_gz_path = os.path.join(new_dir, gz_file)\n",
    "            if gz_file.endswith('.tar.gz'):\n",
    "                extract_tar_gz(new_gz_path, new_dir)\n",
    "            else:\n",
    "                extract_gz(new_gz_path, new_dir)\n",
    "\n",
    "\n",
    "def extract_all():\n",
    "    for subdir in os.listdir(ARTICLES_PATH):\n",
    "        subdir_path = os.path.join(ARTICLES_PATH, subdir)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            process_subdir(subdir_path)\n",
    "\n",
    "\n",
    "extract_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean():\n",
    "    for root, dirs, files in os.walk(ARTICLES_PATH):\n",
    "        for file in files:\n",
    "            if file.endswith('.gz'):\n",
    "                os.remove(os.path.join(root, file))\n",
    "\n",
    "\n",
    "clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class Category(Enum):\n",
    "    AC = 'commutative_algebra'\n",
    "    AG = 'algebraic_geometry'\n",
    "    AP = 'analysis_of_pdes'\n",
    "    AT = 'algebraic_topology'\n",
    "    CA = 'classical_analysis_and_odes'\n",
    "    CO = 'combinatorics'\n",
    "    CT = 'category_theory'\n",
    "    CV = 'complex_variables'\n",
    "    DG = 'differential_geometry'\n",
    "    DS = 'dynamical_systems'\n",
    "    FA = 'functional_analysis'\n",
    "    GM = 'general_mathematics'\n",
    "    GN = 'general_topology'\n",
    "    GR = 'group_theory'\n",
    "    GT = 'geometric_topology'\n",
    "    HO = 'history_and_overview'\n",
    "    IT = 'information_theory'\n",
    "    KT = 'k_theory_and_homology'\n",
    "    LO = 'logic'\n",
    "    MG = 'metric_geometry'\n",
    "    MP = 'mathematical_physics'\n",
    "    NA = 'numerical_analysis'\n",
    "    NT = 'number_theory'\n",
    "    OA = 'operator_algebras'\n",
    "    OC = 'optimization_and_control'\n",
    "    PR = 'probability'\n",
    "    QA = 'quantum_algebra'\n",
    "    RA = 'rings_and_algebras'\n",
    "    RT = 'representation_theory'\n",
    "    SG = 'symplectic_geometry'\n",
    "    SP = 'spectral_theory'\n",
    "    ST = 'statistics_theory'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylatexenc.latexwalker import (\n",
    "    LatexCharsNode,\n",
    "    LatexCommentNode,\n",
    "    LatexEnvironmentNode,\n",
    "    LatexGroupNode,\n",
    "    LatexMacroNode,\n",
    "    LatexMathNode,\n",
    "    LatexNode,\n",
    "    LatexSpecialsNode,\n",
    "    LatexWalker,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'assets/input.tex'\n",
    "\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    latex_str = file.read()\n",
    "\n",
    "walker = LatexWalker(latex_str)\n",
    "\n",
    "(nodes, pos, len_) = walker.get_latex_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_node(root: LatexNode) -> tuple[str, dict[int, LatexMathNode]]:\n",
    "    text = str()\n",
    "    formulas: dict[int, LatexMathNode] = {}\n",
    "    images: dict[int, LatexMacroNode | LatexEnvironmentNode] = {}\n",
    "\n",
    "    stack = [iter([root])]\n",
    "    stack_end = object()\n",
    "\n",
    "    while stack:\n",
    "        node = next(stack[-1], stack_end)\n",
    "\n",
    "        if node is stack_end:\n",
    "            stack.pop()\n",
    "            continue\n",
    "\n",
    "        if isinstance(node, LatexCharsNode):\n",
    "            text += node.chars\n",
    "\n",
    "        elif isinstance(node, LatexMathNode):\n",
    "            i = len(formulas)\n",
    "            formulas[i] = node\n",
    "            text += f'[formula-{i}]'\n",
    "\n",
    "        elif isinstance(node, LatexMacroNode):\n",
    "            if node.macroname == 'includegraphics':\n",
    "                i = len(images)\n",
    "                images[i] = node\n",
    "                text += f'[image-{i}]'\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        elif isinstance(node, LatexEnvironmentNode):\n",
    "            if node.environmentname == 'document':\n",
    "                stack.append(iter(node.nodelist))\n",
    "\n",
    "            elif node.environmentname in ['figure']:\n",
    "                i = len(images)\n",
    "                images[i] = node\n",
    "                text += f'[image-{i}]'\n",
    "\n",
    "            else:\n",
    "                stack.append(iter(node.nodelist))\n",
    "\n",
    "        elif isinstance(node, LatexGroupNode):\n",
    "            stack.append(iter(node.nodelist))\n",
    "\n",
    "        elif isinstance(node, (LatexCommentNode, LatexSpecialsNode)):\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            stack.append(iter(getattr(node, 'nodelist', [])))\n",
    "\n",
    "    return text, formulas\n",
    "\n",
    "\n",
    "doc_env_node = next(\n",
    "    (\n",
    "        node\n",
    "        for node in nodes\n",
    "        if isinstance(node, LatexEnvironmentNode) and node.environmentname == 'document'\n",
    "    ),\n",
    "    None,\n",
    ")\n",
    "\n",
    "if doc_env_node is not None:\n",
    "    extracted_text = parse_node(doc_env_node)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math-rag-jXkTH_HH-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
