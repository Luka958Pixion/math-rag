{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TYPE_CHECKING\n",
    "\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from math_rag.application.containers import ApplicationContainer\n",
    "    from math_rag.infrastructure.containers import InfrastructureContainer\n",
    "\n",
    "    application_container: ApplicationContainer\n",
    "    infrastructure_container: InfrastructureContainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 20:57:27,717 - INFO - PyTorch version 2.6.0 available.\n"
     ]
    }
   ],
   "source": [
    "RESET = False\n",
    "%load_ext hooks.notebook_hook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_katex = r'd\\omega = \\theta \\w \\omega'\n",
    "error = (\n",
    "    r'KaTeX parse error: Undefined control sequence: \\w at position 18: …omega = \\theta \\̲w̲ ̲\\omega'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math_rag.application.models.assistants import KatexCorrectorAssistantInput\n",
    "\n",
    "\n",
    "input = KatexCorrectorAssistantInput(katex=incorrect_katex, error=error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\\omega = \\theta \\wedge \\omega\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Math' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m corrected_katex \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mkatex\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(corrected_katex)\n\u001b[0;32m----> 6\u001b[0m display(\u001b[43mMath\u001b[49m(corrected_katex))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Math' is not defined"
     ]
    }
   ],
   "source": [
    "katex_corrector_assistant = application_container.katex_corrector_assistant()\n",
    "\n",
    "output = await katex_corrector_assistant.assist(input)\n",
    "corrected_katex = output.katex\n",
    "print(corrected_katex)\n",
    "display(Math(corrected_katex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hugging_face_api = infrastructure_container.hugging_face_api()\n",
    "hugging_face_username = infrastructure_container.config.hugging_face.username()\n",
    "hugging_face_token = infrastructure_container.config.hugging_face.token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets.download import DownloadConfig\n",
    "\n",
    "\n",
    "repo_id = f'{hugging_face_username}/mathexpressiondataset'\n",
    "\n",
    "download_config = DownloadConfig(\n",
    "    max_retries=3,\n",
    "    disable_tqdm=True,\n",
    ")\n",
    "\n",
    "dataset_dict = load_dataset(\n",
    "    path=repo_id,\n",
    "    split=None,\n",
    "    download_config=download_config,\n",
    "    token=hugging_face_token,\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['equality', 'inequality', 'constant', 'variable', 'other']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import cast\n",
    "\n",
    "from datasets import ClassLabel\n",
    "\n",
    "\n",
    "class_label = cast(ClassLabel, dataset_dict['train'].features['label'])\n",
    "class_label.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in dataset_dict['train']:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI finish reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_with_length_finish_reason = {\n",
    "    'id': 'batch_req_68338415d224819095e7e42c4aeac8f8',\n",
    "    'custom_id': 'b9b237e5-d1c8-4348-9c90-f29e998228a6',\n",
    "    'response': {\n",
    "        'status_code': 200,\n",
    "        'request_id': 'a12fbd18fe2366571f083c2b6e707c96',\n",
    "        'body': {\n",
    "            'id': 'chatcmpl-BbB9Kx0P0WJlR2r4I1SuRkYa2Mvn0',\n",
    "            'object': 'chat.completion',\n",
    "            'created': 1748200694,\n",
    "            'model': 'gpt-4.1-nano-2025-04-14',\n",
    "            'choices': [\n",
    "                {\n",
    "                    'index': 0,\n",
    "                    'message': {\n",
    "                        'role': 'assistant',\n",
    "                        'content': 'some too long content...',\n",
    "                        'refusal': None,\n",
    "                        'annotations': [],\n",
    "                    },\n",
    "                    'logprobs': None,\n",
    "                    'finish_reason': 'length',\n",
    "                }\n",
    "            ],\n",
    "            'usage': {\n",
    "                'prompt_tokens': 285,\n",
    "                'completion_tokens': 1024,\n",
    "                'total_tokens': 1309,\n",
    "                'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0},\n",
    "                'completion_tokens_details': {\n",
    "                    'reasoning_tokens': 0,\n",
    "                    'audio_tokens': 0,\n",
    "                    'accepted_prediction_tokens': 0,\n",
    "                    'rejected_prediction_tokens': 0,\n",
    "                },\n",
    "            },\n",
    "            'service_tier': 'default',\n",
    "            'system_fingerprint': 'fp_eede8f0d45',\n",
    "        },\n",
    "    },\n",
    "    'error': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length\n"
     ]
    },
    {
     "ename": "LengthFinishReasonError",
     "evalue": "Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=1024, prompt_tokens=285, total_tokens=1309, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLengthFinishReasonError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28mprint\u001b[39m(choice\u001b[38;5;241m.\u001b[39mfinish_reason)\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[43mparse_chat_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNOT_GIVEN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNOT_GIVEN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchat_completion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchat_completion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/.venv/lib/python3.12/site-packages/openai/lib/_parsing/_completions.py:72\u001b[0m, in \u001b[0;36mparse_chat_completion\u001b[0;34m(response_format, input_tools, chat_completion)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m choice \u001b[38;5;129;01min\u001b[39;00m chat_completion\u001b[38;5;241m.\u001b[39mchoices:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m choice\u001b[38;5;241m.\u001b[39mfinish_reason \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 72\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LengthFinishReasonError(completion\u001b[38;5;241m=\u001b[39mchat_completion)\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m choice\u001b[38;5;241m.\u001b[39mfinish_reason \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_filter\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ContentFilterFinishReasonError()\n",
      "\u001b[0;31mLengthFinishReasonError\u001b[0m: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=1024, prompt_tokens=285, total_tokens=1309, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))"
     ]
    }
   ],
   "source": [
    "from openai import NOT_GIVEN\n",
    "from openai.lib._parsing._completions import (\n",
    "    parse_chat_completion,\n",
    ")\n",
    "from openai.types.chat import ChatCompletion\n",
    "\n",
    "\n",
    "chat_completion = ChatCompletion(**response_with_length_finish_reason['response']['body'])\n",
    "\n",
    "for choice in chat_completion.choices:\n",
    "    if choice.finish_reason == 'length' or choice.finish_reason == 'content_filter':\n",
    "        print(choice.finish_reason)\n",
    "        pass\n",
    "\n",
    "target = parse_chat_completion(\n",
    "    response_format=NOT_GIVEN,\n",
    "    input_tools=NOT_GIVEN,\n",
    "    chat_completion=chat_completion,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import UUID\n",
    "\n",
    "\n",
    "importer_service = application_container.math_expression_label_task_importer_service()\n",
    "exporter_service = application_container.math_expression_label_exporter_service()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 20:57:44,787 - INFO - Project mathexpressionlabeltask created\n",
      "2025-06-18 20:57:44,817 - INFO - Imported 2 tasks into mathexpressionlabeltask\n"
     ]
    }
   ],
   "source": [
    "project_id = await importer_service.import_tasks(\n",
    "    None, dataset_id=UUID('1260dfdb-8c6a-4001-a007-1c60766a6754'), split_name='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MathExpressionLabel(id=UUID('4f847ae9-000c-4c6c-824e-036a6e7cf99e'), math_expression_id=UUID('d5bf6a13-502a-48e1-a508-31c75c30b0ec'), math_expression_dataset_id=UUID('1260dfdb-8c6a-4001-a007-1c60766a6754'), index_id=None, timestamp=datetime.datetime(2025, 6, 18, 15, 6, 59, 357000, tzinfo=TzInfo(UTC)), value=<MathExpressionLabelEnum.INEQUALITY: 'inequality'>),\n",
       " MathExpressionLabel(id=UUID('8754c627-1fc4-4107-8de3-a4c0629cfa2d'), math_expression_id=UUID('d5e70102-2a3b-431c-8b11-70f93e2440c2'), math_expression_dataset_id=UUID('1260dfdb-8c6a-4001-a007-1c60766a6754'), index_id=None, timestamp=datetime.datetime(2025, 6, 18, 15, 6, 59, 357000, tzinfo=TzInfo(UTC)), value=<MathExpressionLabelEnum.VARIABLE: 'variable'>)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = await exporter_service.export(project_id)\n",
    "labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
