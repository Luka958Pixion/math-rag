{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config\n",
    "\n",
    "from math_rag.repositories.embeddings import QdrantEmbeddingRepository\n",
    "from math_rag.repositories.files import MinioFileRepository\n",
    "from math_rag.repositories.graphs import Neo4jGraphRepository\n",
    "from math_rag.repositories.objects import MongoObjectRepository\n",
    "\n",
    "\n",
    "DEPLOYMENT = config('DEPLOYMENT')\n",
    "\n",
    "MINIO_ENDPOINT = config('MINIO_ENDPOINT')\n",
    "MINIO_ACCESS_KEY = config('MINIO_ACCESS_KEY')\n",
    "MINIO_SECRET_KEY = config('MINIO_SECRET_KEY')\n",
    "MONGO_HOST = config('MONGO_HOST')\n",
    "NEO4J_URI = config('NEO4J_URI')\n",
    "NEO4J_USERNAME = config('NEO4J_USERNAME')\n",
    "NEO4J_PASSWORD = config('NEO4J_PASSWORD')\n",
    "QDRANT_URL = config('QDRANT_URL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_repo = MinioFileRepository(MINIO_ENDPOINT, MINIO_ACCESS_KEY, MINIO_SECRET_KEY)\n",
    "embedding_repo = QdrantEmbeddingRepository(QDRANT_URL)\n",
    "graph_repo = Neo4jGraphRepository(NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    "object_repo = MongoObjectRepository(MONGO_HOST, DEPLOYMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "import tarfile\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from pylatexenc.latexwalker import (\n",
    "    LatexCharsNode,\n",
    "    LatexCommentNode,\n",
    "    LatexEnvironmentNode,\n",
    "    LatexGroupNode,\n",
    "    LatexMacroNode,\n",
    "    LatexMathNode,\n",
    "    LatexNode,\n",
    "    LatexSpecialsNode,\n",
    "    LatexWalker,\n",
    ")\n",
    "\n",
    "\n",
    "ARTICLES_PATH = '../tmp/articles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import Resource, build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "\n",
    "\n",
    "def authenticate() -> Resource:\n",
    "    token_path = Path('../google/token.json')\n",
    "    credentials: Credentials | None = None\n",
    "\n",
    "    if token_path.exists():\n",
    "        credentials = Credentials.from_authorized_user_file(str(token_path), SCOPES)\n",
    "\n",
    "    if not credentials or not credentials.valid:\n",
    "        if credentials and credentials.expired and credentials.refresh_token:\n",
    "            credentials.refresh(Request())\n",
    "\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                '../google/credentials.json', SCOPES\n",
    "            )\n",
    "            credentials = flow.run_local_server(port=0)\n",
    "\n",
    "        token_path.write_text(credentials.to_json())\n",
    "\n",
    "    return build('drive', 'v3', credentials=credentials)\n",
    "\n",
    "\n",
    "def get_file_id(service: Resource, file_name: str, dir_name: str) -> str | None:\n",
    "    dir_query = f\"name='{dir_name}' and mimeType='application/vnd.google-apps.folder'\"\n",
    "    dir_fields = 'files(id, name)'\n",
    "    dir_results: dict = (\n",
    "        service.files()\n",
    "        .list(\n",
    "            q=dir_query,\n",
    "            fields=dir_fields,\n",
    "        )\n",
    "        .execute()\n",
    "    )\n",
    "    dirs = dir_results.get('files', [])\n",
    "\n",
    "    if not dirs:\n",
    "        logging.info(f'Directory {dir_name} not found.')\n",
    "        return None\n",
    "\n",
    "    dir_id = dirs[0]['id']\n",
    "\n",
    "    file_query = f\"name='{file_name}' and '{dir_id}' in parents\"\n",
    "    file_fields = 'files(id, name)'\n",
    "    file_results = service.files().list(q=file_query, fields=file_fields).execute()\n",
    "    files = file_results.get('files', [])\n",
    "\n",
    "    if not files:\n",
    "        logging.info(f'File {file_name} not found in directory {dir_name}.')\n",
    "        return None\n",
    "\n",
    "    return files[0]['id']\n",
    "\n",
    "\n",
    "def download_file(service: Resource, file_id: str) -> BytesIO:\n",
    "    request = service.files().get_media(fileId=file_id)\n",
    "    file_bytes = BytesIO()\n",
    "\n",
    "    downloader = MediaIoBaseDownload(file_bytes, request)\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        _, done = downloader.next_chunk()\n",
    "\n",
    "    return file_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lukap/math-rag/notebooks\n",
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=740655027153-0682f6qfp13qk1oh917pno162crrseaq.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A52179%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&state=nz6VROXkZvZlsdbfluZ2OWnCz8Mbmb&access_type=offline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gio: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=740655027153-0682f6qfp13qk1oh917pno162crrseaq.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A52179%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&state=nz6VROXkZvZlsdbfluZ2OWnCz8Mbmb&access_type=offline: Operation not supported\n"
     ]
    }
   ],
   "source": [
    "service = authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'articles'\n",
    "file_name = 'articles_v1.zip'\n",
    "\n",
    "file_id = get_file_id(service, file_name, dir_name)\n",
    "\n",
    "if file_id:\n",
    "    file_bytes = download_file(service, file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "\n",
    "with ZipFile(file_bytes, 'r') as zip_file:\n",
    "    file_dict = {name: BytesIO(zip_file.read(name)) for name in zip_file.namelist()}\n",
    "\n",
    "file_name, file_bytes = file_dict.items()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'articles'\n",
    "file_repo.create_bucket(bucket_name)\n",
    "file_repo.insert_file(bucket_name, file_name, file_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15043/154124979.py:39: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall(path=dest_folder)\n"
     ]
    }
   ],
   "source": [
    "def get_gzip_original_filename(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        if f.read(2) != b'\\x1f\\x8b':\n",
    "            return None\n",
    "        f.read(1)\n",
    "        flag = f.read(1)[0]\n",
    "        f.read(4)\n",
    "        f.read(1)\n",
    "        f.read(1)\n",
    "        orig_name = None\n",
    "        if flag & 0x08:\n",
    "            name_bytes = bytearray()\n",
    "            while True:\n",
    "                b = f.read(1)\n",
    "                if not b or b == b'\\x00':\n",
    "                    break\n",
    "                name_bytes.extend(b)\n",
    "            try:\n",
    "                orig_name = name_bytes.decode('utf-8')\n",
    "            except UnicodeDecodeError:\n",
    "                orig_name = name_bytes.decode('latin1')\n",
    "        return orig_name\n",
    "\n",
    "\n",
    "def extract_gz(file_path, dest_folder):\n",
    "    orig_name = get_gzip_original_filename(file_path)\n",
    "    if not orig_name:\n",
    "        orig_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    dest_path = os.path.join(dest_folder, orig_name)\n",
    "    with gzip.open(file_path, 'rb') as f_in, open(dest_path, 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "\n",
    "def extract_tar_gz(file_path, dest_folder):\n",
    "    with tarfile.open(file_path, 'r:gz') as tar:\n",
    "        tar.extractall(path=dest_folder)\n",
    "\n",
    "\n",
    "def process_subdir(subdir_path):\n",
    "    files = os.listdir(subdir_path)\n",
    "    pdf_files = {f for f in files if f.endswith('.pdf')}\n",
    "    for pdf in pdf_files:\n",
    "        base_name = pdf[:-4]\n",
    "        gz_name = f'arXiv-{base_name}.gz'\n",
    "        tar_gz_name = f'arXiv-{base_name}.tar.gz'\n",
    "        gz_file = None\n",
    "        if tar_gz_name in files:\n",
    "            gz_file = tar_gz_name\n",
    "        elif gz_name in files:\n",
    "            gz_file = gz_name\n",
    "        if gz_file:\n",
    "            new_dir = os.path.join(subdir_path, base_name)\n",
    "            os.makedirs(new_dir, exist_ok=True)\n",
    "            shutil.move(os.path.join(subdir_path, pdf), new_dir)\n",
    "            shutil.move(os.path.join(subdir_path, gz_file), new_dir)\n",
    "            new_gz_path = os.path.join(new_dir, gz_file)\n",
    "            if gz_file.endswith('.tar.gz'):\n",
    "                extract_tar_gz(new_gz_path, new_dir)\n",
    "            else:\n",
    "                extract_gz(new_gz_path, new_dir)\n",
    "\n",
    "\n",
    "def extract_all():\n",
    "    for subdir in os.listdir(ARTICLES_PATH):\n",
    "        subdir_path = os.path.join(ARTICLES_PATH, subdir)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            process_subdir(subdir_path)\n",
    "\n",
    "\n",
    "extract_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean():\n",
    "    for root, dirs, files in os.walk(ARTICLES_PATH):\n",
    "        for file in files:\n",
    "            if file.endswith('.gz'):\n",
    "                os.remove(os.path.join(root, file))\n",
    "\n",
    "\n",
    "clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class ArXivMathCategory(str, Enum):\n",
    "    AC = 'commutative_algebra'\n",
    "    AG = 'algebraic_geometry'\n",
    "    AP = 'analysis_of_pdes'\n",
    "    AT = 'algebraic_topology'\n",
    "    CA = 'classical_analysis_and_odes'\n",
    "    CO = 'combinatorics'\n",
    "    CT = 'category_theory'\n",
    "    CV = 'complex_variables'\n",
    "    DG = 'differential_geometry'\n",
    "    DS = 'dynamical_systems'\n",
    "    FA = 'functional_analysis'\n",
    "    GM = 'general_mathematics'\n",
    "    GN = 'general_topology'\n",
    "    GR = 'group_theory'\n",
    "    GT = 'geometric_topology'\n",
    "    HO = 'history_and_overview'\n",
    "    IT = 'information_theory'\n",
    "    KT = 'k_theory_and_homology'\n",
    "    LO = 'logic'\n",
    "    MG = 'metric_geometry'\n",
    "    MP = 'mathematical_physics'\n",
    "    NA = 'numerical_analysis'\n",
    "    NT = 'number_theory'\n",
    "    OA = 'operator_algebras'\n",
    "    OC = 'optimization_and_control'\n",
    "    PR = 'probability'\n",
    "    QA = 'quantum_algebra'\n",
    "    RA = 'rings_and_algebras'\n",
    "    RT = 'representation_theory'\n",
    "    SG = 'symplectic_geometry'\n",
    "    SP = 'spectral_theory'\n",
    "    ST = 'statistics_theory'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tex_file(file_path: Path) -> tuple[str, str]:\n",
    "    for encoding in ('utf-8', 'latin1', 'cp1252'):\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding=encoding) as file:\n",
    "                return file.read(), encoding\n",
    "\n",
    "        except UnicodeDecodeError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylatexenc.macrospec import ParsedMacroArgs\n",
    "\n",
    "\n",
    "def visit_nodes_old(file_path: Path):\n",
    "    latex, encoding = read_tex_file(file_path)\n",
    "    walker = LatexWalker(latex)\n",
    "    nodes, _, _ = walker.get_latex_nodes()\n",
    "\n",
    "    stack = [iter(nodes)]\n",
    "\n",
    "    while stack:\n",
    "        node = next(stack[-1], None)\n",
    "\n",
    "        if node is None:\n",
    "            stack.pop()\n",
    "            continue\n",
    "\n",
    "        if isinstance(node, LatexCharsNode):\n",
    "            pass\n",
    "\n",
    "        elif isinstance(node, LatexMathNode):\n",
    "            pass\n",
    "\n",
    "        elif isinstance(node, LatexCommentNode):\n",
    "            pass\n",
    "\n",
    "        elif isinstance(node, LatexSpecialsNode):\n",
    "            pass\n",
    "\n",
    "        elif isinstance(node, LatexMacroNode):\n",
    "            # if node.macroname == 'input':\n",
    "            #     args: ParsedMacroArgs = node.nodeargd\n",
    "            #     assert len(args.argnlist) == 1\n",
    "\n",
    "            #     group_node = args.argnlist[0]\n",
    "            #     if not isinstance(group_node, LatexGroupNode):\n",
    "            #         continue\n",
    "\n",
    "            #     assert len(group_node.nodelist) == 1\n",
    "\n",
    "            #     chars_node: LatexCharsNode = group_node.nodelist[0]\n",
    "            #     input_file_name = str(chars_node.chars)\n",
    "            #     input_file_path = dir_path / input_file_name\n",
    "\n",
    "            #     if not input_file_path.suffix:\n",
    "            #         input_file_path = input_file_path.with_suffix('.tex')\n",
    "\n",
    "            #     if input_file_path.suffix == '.tex':\n",
    "            #         latex, encoding = read_tex_file(input_file_path)\n",
    "            #         walker = LatexWalker(latex)\n",
    "            #         nodes, _, _ = walker.get_latex_nodes()\n",
    "            #         stack.append(iter(nodes))\n",
    "\n",
    "            # elif node.macroname == 'include':\n",
    "            #     pass\n",
    "            pass\n",
    "\n",
    "        elif isinstance(node, LatexEnvironmentNode):\n",
    "            stack.append(iter(node.nodelist))\n",
    "\n",
    "        elif isinstance(node, LatexGroupNode):\n",
    "            stack.append(iter(node.nodelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Iterator\n",
    "\n",
    "\n",
    "def visit_nodes(\n",
    "    file_path: Path, callbacks: dict[type[LatexNode], Callable[[LatexNode], None]]\n",
    "):\n",
    "    latex, _ = read_tex_file(file_path)\n",
    "    walker = LatexWalker(latex)\n",
    "    nodes, _, _ = walker.get_latex_nodes()\n",
    "\n",
    "    stack: list[Iterator[LatexNode]] = [iter(nodes)]\n",
    "\n",
    "    while stack:\n",
    "        node = next(stack[-1], None)\n",
    "\n",
    "        if node is None:\n",
    "            stack.pop()\n",
    "            continue\n",
    "\n",
    "        node_type = type(node)\n",
    "\n",
    "        if node_type in callbacks:\n",
    "            callbacks[node_type](node)\n",
    "\n",
    "        if isinstance(node, LatexEnvironmentNode) or isinstance(node, LatexGroupNode):\n",
    "            stack.append(iter(node.nodelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127133"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE:\n",
    "# problem with multiple .tex files -> which one is root? -> one with doc env node?\n",
    "# problem with relative \\input{} -> root dir needed, i.e., .../2502.13810v1\n",
    "\n",
    "math_nodes: list[LatexMathNode] = []\n",
    "append_math_node = lambda x: math_nodes.append(x)\n",
    "\n",
    "callbacks = {LatexMathNode: append_math_node}\n",
    "\n",
    "for file_path in Path(ARTICLES_PATH).rglob('*.tex'):\n",
    "    visit_nodes(file_path, callbacks)\n",
    "\n",
    "len(math_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import UUID, uuid4\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class MathExpressionRecord(BaseModel):\n",
    "    id: UUID = Field(default_factory=uuid4)\n",
    "    latex: str\n",
    "    position: int\n",
    "    is_inline: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_latex(latex_str: str):\n",
    "    fixed = latex_str.replace('\\\\[', '$$').replace('\\\\]', '$$')\n",
    "    fixed = fixed.replace('\\\\EE', '\\\\mathbb{E}')\n",
    "    fixed = fixed.replace('\\\\II', '\\\\mathbb{I}')\n",
    "    fixed = fixed.replace('\\\\Var', '\\\\mathrm{Var}')\n",
    "    fixed = fixed.replace('\\\\HH', '\\\\mathbb{H}')\n",
    "    fixed = fixed.replace('\\\\AND', '\\\\wedge')\n",
    "    fixed = fixed.replace('\\\\OR', '\\\\vee')\n",
    "    fixed = fixed.replace('\\\\mathbbm{1}', '\\\\mathbf{1}')\n",
    "    fixed = fixed.replace('\\\\Maj', '\\\\mathrm{Maj}')\n",
    "    fixed = fixed.replace('\\\\sgn', '\\\\operatorname{sgn}')\n",
    "    fixed = fixed.replace('\\\\Tribus', '\\\\mathrm{Tribus}')\n",
    "    fixed = fixed.replace('\\\\linebreak', '\\\\text{ }')\n",
    "    fixed = fixed.replace('\\\\Prob', '\\\\mathbb{P}')\n",
    "    fixed = fixed.replace('\\\\WW', '\\\\mathcal{W}')\n",
    "\n",
    "    return fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Math, display\n",
    "\n",
    "\n",
    "for i, latex_math_node in enumerate(math_nodes[:100]):\n",
    "    latex = latex_math_node.latex_verbatim()\n",
    "    latex_fixed = fix_latex(latex)\n",
    "    math_display_object = Math(latex_fixed)\n",
    "\n",
    "    # print(i)\n",
    "    # print(math_display_object._repr_latex_())\n",
    "\n",
    "    display(math_display_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config\n",
    "\n",
    "from math_rag.inference.llms import LLM\n",
    "\n",
    "\n",
    "OPENAI_BASE_URL = config('OPENAI_BASE_URL')\n",
    "OPENAI_API_KEY = config('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(model='gpt-4o-mini', base_url=OPENAI_BASE_URL, api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$\\\\mu(x)=\\\\frac{1}{2^n}$'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_expr = math_nodes[13].latex_verbatim()  # 13\n",
    "math_expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-B3qibSoK3Z0LqPtZQjEYKhXO1AjaF', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='formula', bytes=[102, 111, 114, 109, 117, 108, 97], logprob=-3.1281633e-07, top_logprobs=[TopLogprob(token='formula', bytes=[102, 111, 114, 109, 117, 108, 97], logprob=-3.1281633e-07), TopLogprob(token=' formula', bytes=[32, 102, 111, 114, 109, 117, 108, 97], logprob=-16.125), TopLogprob(token='Formula', bytes=[70, 111, 114, 109, 117, 108, 97], logprob=-16.375), TopLogprob(token='_formula', bytes=[95, 102, 111, 114, 109, 117, 108, 97], logprob=-18.5), TopLogprob(token='form', bytes=[102, 111, 114, 109], logprob=-20.0)])], refusal=None), message=ChatCompletionMessage(content='formula', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740257333, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_7fcd609668', usage=CompletionUsage(completion_tokens=2, prompt_tokens=68, total_tokens=70, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "from openai import NOT_GIVEN\n",
    "\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are a mathematical expression classifier.\n",
    "Given a mathematical expression, classify it in one of 4 given classes:\n",
    "- constant\n",
    "- variable\n",
    "- formula\n",
    "- other\n",
    "\n",
    "Return a class only!\n",
    "\n",
    "Mathematical expression:\n",
    "{math_expr}\n",
    "\n",
    "Class:\n",
    "\"\"\"\n",
    "\n",
    "use_json = False\n",
    "completion = await llm.client.chat.completions.create(\n",
    "    model=llm.model,\n",
    "    messages=[{'role': 'user', 'content': prompt}],\n",
    "    response_format={'type': 'json_object'} if use_json else NOT_GIVEN,\n",
    "    logprobs=True,\n",
    "    temperature=0.0,\n",
    "    top_logprobs=5,\n",
    ")\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'formula'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"formula\": 0.9999996871837189\n",
      "\" formula\": 9.931194312156244e-08\n",
      "\"Formula\": 7.734421907141565e-08\n",
      "\"_formula\": 9.237449661970594e-09\n",
      "\"form\": 2.061153622438558e-09\n",
      "------\n",
      "formula\n",
      "-3.1281633e-07\n",
      "0.9999996871837189\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "for x in completion.choices[0].logprobs.content:\n",
    "    for y in x.top_logprobs:\n",
    "        print(f'\"{y.token}\": {np.exp(y.logprob)}')\n",
    "\n",
    "    print('------')\n",
    "    print(x.token)\n",
    "    print(x.logprob)\n",
    "    print(np.exp(x.logprob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# - description for each class\n",
    "# - how to determine classes?\n",
    "# - do names need to take a single token?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathExpressionCategory(str, Enum):\n",
    "    CONSTANT = 'constant'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math-rag-jXkTH_HH-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
