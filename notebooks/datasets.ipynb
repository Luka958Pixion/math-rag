{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "# logging.getLogger('pylatexenc.latexwalker').setLevel(logging.ERROR)\n",
    "# logging.getLogger('httpx').setLevel(logging.WARNING)\n",
    "# logging.getLogger('openai').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 23:30:55,234 - INFO - HTTP Request: GET http://qdrant:6333 \"HTTP/1.1 200 OK\"\n",
      "2025-06-13 23:30:55,239 - INFO - HTTP Request: DELETE http://qdrant:6333/collections/mathexpressiondescriptionembedding \"HTTP/1.1 200 OK\"\n",
      "2025-06-13 23:30:55,240 - INFO - HTTP Request: GET http://qdrant:6333/collections/mathexpressiondescriptionembedding/exists \"HTTP/1.1 200 OK\"\n",
      "2025-06-13 23:30:55,299 - INFO - HTTP Request: PUT http://qdrant:6333/collections/mathexpressiondescriptionembedding \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from math_rag.infrastructure.containers import InfrastructureContainer\n",
    "\n",
    "\n",
    "RESET = True\n",
    "\n",
    "# containers\n",
    "infrastructure_container = InfrastructureContainer()\n",
    "infrastructure_container.init_resources()\n",
    "infrastructure_container.wire(modules=[__name__])\n",
    "\n",
    "application_container = infrastructure_container.application_container()\n",
    "application_container.init_resources()\n",
    "application_container.wire(modules=[__name__])\n",
    "\n",
    "# seed\n",
    "for object_seeder in infrastructure_container.object_seeders():\n",
    "    object_seeder.seed(reset=RESET)\n",
    "\n",
    "for document_seeder in infrastructure_container.document_seeders():\n",
    "    await document_seeder.seed(reset=RESET)\n",
    "\n",
    "for embedding_seeder in infrastructure_container.embedding_seeders():\n",
    "    await embedding_seeder.seed(reset=RESET)\n",
    "\n",
    "# index\n",
    "for document_indexer in infrastructure_container.document_indexers():\n",
    "    await document_indexer.index(reset=RESET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import UUID\n",
    "\n",
    "from math_rag.core.enums import MathExpressionDatasetBuildStage\n",
    "from math_rag.core.models import MathExpressionDataset\n",
    "\n",
    "\n",
    "math_expression_dataset_builder_service = (\n",
    "    application_container.math_expression_dataset_builder_service()\n",
    ")\n",
    "math_expression_dataset_repository = application_container.math_expression_dataset_repository()\n",
    "\n",
    "\n",
    "current_dataset = MathExpressionDataset(\n",
    "    # build_from_dataset_id=UUID('dd5b1e2d-dc0c-4ae9-9f24-2fd2d37f42fa'),\n",
    "    # build_from_stage=MathExpressionDatasetBuildStage.LOAD_MATH_EXPRESSION_SAMPLES,\n",
    ")\n",
    "await math_expression_dataset_repository.insert_one(current_dataset)\n",
    "await math_expression_dataset_builder_service.build(current_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$defs': {'MathExpressionLabelEnum': {'enum': ['equality',\n",
       "    'inequality',\n",
       "    'constant',\n",
       "    'variable',\n",
       "    'other'],\n",
       "   'title': 'MathExpressionLabelEnum',\n",
       "   'type': 'string'}},\n",
       " 'properties': {'label': {'$ref': '#/$defs/MathExpressionLabelEnum'}},\n",
       " 'required': ['label'],\n",
       " 'title': 'MathExpressionLabelerAssistantOutput',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math_rag.application.models.assistants import MathExpressionLabelerAssistantOutput\n",
    "\n",
    "\n",
    "MathExpressionLabelerAssistantOutput.model_json_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_katex = r'd\\omega = \\theta \\w \\omega'\n",
    "error = (\n",
    "    r'KaTeX parse error: Undefined control sequence: \\w at position 18: …omega = \\theta \\̲w̲ ̲\\omega'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math_rag.application.models.assistants import KatexCorrectorAssistantInput\n",
    "\n",
    "\n",
    "input = KatexCorrectorAssistantInput(katex=incorrect_katex, error=error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "katex_corrector_assistant = application_container.katex_corrector_assistant()\n",
    "\n",
    "output = await katex_corrector_assistant.assist(input)\n",
    "corrected_katex = output.katex\n",
    "print(corrected_katex)\n",
    "display(Math(corrected_katex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets.download import DownloadConfig\n",
    "from decouple import config\n",
    "\n",
    "\n",
    "HF_USERNAME = config('HF_USERNAME', default=None)\n",
    "HF_TOKEN = config('HF_TOKEN', default=None)\n",
    "\n",
    "download_config = DownloadConfig(\n",
    "    max_retries=3,\n",
    "    disable_tqdm=True,\n",
    ")\n",
    "\n",
    "dataset_dict = load_dataset(\n",
    "    path=f'{HF_USERNAME}/mathexpressiondataset',\n",
    "    split=None,\n",
    "    download_config=download_config,\n",
    "    token=HF_TOKEN,\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['equality', 'inequality', 'constant', 'variable', 'other']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import cast\n",
    "\n",
    "from datasets import ClassLabel\n",
    "\n",
    "\n",
    "class_label = cast(ClassLabel, dataset_dict['train'].features['label'])\n",
    "class_label.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI finish reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_with_length_finish_reason = {\n",
    "    'id': 'batch_req_68338415d224819095e7e42c4aeac8f8',\n",
    "    'custom_id': 'b9b237e5-d1c8-4348-9c90-f29e998228a6',\n",
    "    'response': {\n",
    "        'status_code': 200,\n",
    "        'request_id': 'a12fbd18fe2366571f083c2b6e707c96',\n",
    "        'body': {\n",
    "            'id': 'chatcmpl-BbB9Kx0P0WJlR2r4I1SuRkYa2Mvn0',\n",
    "            'object': 'chat.completion',\n",
    "            'created': 1748200694,\n",
    "            'model': 'gpt-4.1-nano-2025-04-14',\n",
    "            'choices': [\n",
    "                {\n",
    "                    'index': 0,\n",
    "                    'message': {\n",
    "                        'role': 'assistant',\n",
    "                        'content': 'some too long content...',\n",
    "                        'refusal': None,\n",
    "                        'annotations': [],\n",
    "                    },\n",
    "                    'logprobs': None,\n",
    "                    'finish_reason': 'length',\n",
    "                }\n",
    "            ],\n",
    "            'usage': {\n",
    "                'prompt_tokens': 285,\n",
    "                'completion_tokens': 1024,\n",
    "                'total_tokens': 1309,\n",
    "                'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0},\n",
    "                'completion_tokens_details': {\n",
    "                    'reasoning_tokens': 0,\n",
    "                    'audio_tokens': 0,\n",
    "                    'accepted_prediction_tokens': 0,\n",
    "                    'rejected_prediction_tokens': 0,\n",
    "                },\n",
    "            },\n",
    "            'service_tier': 'default',\n",
    "            'system_fingerprint': 'fp_eede8f0d45',\n",
    "        },\n",
    "    },\n",
    "    'error': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length\n"
     ]
    },
    {
     "ename": "LengthFinishReasonError",
     "evalue": "Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=1024, prompt_tokens=285, total_tokens=1309, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLengthFinishReasonError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28mprint\u001b[39m(choice\u001b[38;5;241m.\u001b[39mfinish_reason)\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[43mparse_chat_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNOT_GIVEN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNOT_GIVEN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchat_completion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchat_completion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/.venv/lib/python3.12/site-packages/openai/lib/_parsing/_completions.py:72\u001b[0m, in \u001b[0;36mparse_chat_completion\u001b[0;34m(response_format, input_tools, chat_completion)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m choice \u001b[38;5;129;01min\u001b[39;00m chat_completion\u001b[38;5;241m.\u001b[39mchoices:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m choice\u001b[38;5;241m.\u001b[39mfinish_reason \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 72\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LengthFinishReasonError(completion\u001b[38;5;241m=\u001b[39mchat_completion)\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m choice\u001b[38;5;241m.\u001b[39mfinish_reason \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_filter\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ContentFilterFinishReasonError()\n",
      "\u001b[0;31mLengthFinishReasonError\u001b[0m: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=1024, prompt_tokens=285, total_tokens=1309, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))"
     ]
    }
   ],
   "source": [
    "from openai import NOT_GIVEN\n",
    "from openai.lib._parsing._completions import (\n",
    "    parse_chat_completion,\n",
    ")\n",
    "from openai.types.chat import ChatCompletion\n",
    "\n",
    "\n",
    "chat_completion = ChatCompletion(**response_with_length_finish_reason['response']['body'])\n",
    "\n",
    "for choice in chat_completion.choices:\n",
    "    if choice.finish_reason == 'length' or choice.finish_reason == 'content_filter':\n",
    "        print(choice.finish_reason)\n",
    "        pass\n",
    "\n",
    "target = parse_chat_completion(\n",
    "    response_format=NOT_GIVEN,\n",
    "    input_tools=NOT_GIVEN,\n",
    "    chat_completion=chat_completion,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<enum 'MathCategory'>\n"
     ]
    }
   ],
   "source": [
    "from math_rag.core.enums.arxiv import MathCategory\n",
    "\n",
    "\n",
    "print(str(MathCategory.AC.__class__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'math_rag.core.enums.arxiv.MathCategory'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math_rag.shared.utils import TypeUtil\n",
    "\n",
    "\n",
    "TypeUtil.to_fqn(MathCategory.AC.__class__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
