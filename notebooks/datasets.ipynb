{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "import tarfile\n",
    "\n",
    "from pylatexenc.latexwalker import (\n",
    "    LatexCharsNode,\n",
    "    LatexCommentNode,\n",
    "    LatexEnvironmentNode,\n",
    "    LatexGroupNode,\n",
    "    LatexMacroNode,\n",
    "    LatexMathNode,\n",
    "    LatexNode,\n",
    "    LatexSpecialsNode,\n",
    "    LatexWalker,\n",
    ")\n",
    "\n",
    "\n",
    "ARTICLES_PATH = '../tmp/articles'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15043/154124979.py:39: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall(path=dest_folder)\n"
     ]
    }
   ],
   "source": [
    "def get_gzip_original_filename(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        if f.read(2) != b'\\x1f\\x8b':\n",
    "            return None\n",
    "        f.read(1)\n",
    "        flag = f.read(1)[0]\n",
    "        f.read(4)\n",
    "        f.read(1)\n",
    "        f.read(1)\n",
    "        orig_name = None\n",
    "        if flag & 0x08:\n",
    "            name_bytes = bytearray()\n",
    "            while True:\n",
    "                b = f.read(1)\n",
    "                if not b or b == b'\\x00':\n",
    "                    break\n",
    "                name_bytes.extend(b)\n",
    "            try:\n",
    "                orig_name = name_bytes.decode('utf-8')\n",
    "            except UnicodeDecodeError:\n",
    "                orig_name = name_bytes.decode('latin1')\n",
    "        return orig_name\n",
    "\n",
    "\n",
    "def extract_gz(file_path, dest_folder):\n",
    "    orig_name = get_gzip_original_filename(file_path)\n",
    "    if not orig_name:\n",
    "        orig_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    dest_path = os.path.join(dest_folder, orig_name)\n",
    "    with gzip.open(file_path, 'rb') as f_in, open(dest_path, 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "\n",
    "def extract_tar_gz(file_path, dest_folder):\n",
    "    with tarfile.open(file_path, 'r:gz') as tar:\n",
    "        tar.extractall(path=dest_folder)\n",
    "\n",
    "\n",
    "def process_subdir(subdir_path):\n",
    "    files = os.listdir(subdir_path)\n",
    "    pdf_files = {f for f in files if f.endswith('.pdf')}\n",
    "    for pdf in pdf_files:\n",
    "        base_name = pdf[:-4]\n",
    "        gz_name = f'arXiv-{base_name}.gz'\n",
    "        tar_gz_name = f'arXiv-{base_name}.tar.gz'\n",
    "        gz_file = None\n",
    "        if tar_gz_name in files:\n",
    "            gz_file = tar_gz_name\n",
    "        elif gz_name in files:\n",
    "            gz_file = gz_name\n",
    "        if gz_file:\n",
    "            new_dir = os.path.join(subdir_path, base_name)\n",
    "            os.makedirs(new_dir, exist_ok=True)\n",
    "            shutil.move(os.path.join(subdir_path, pdf), new_dir)\n",
    "            shutil.move(os.path.join(subdir_path, gz_file), new_dir)\n",
    "            new_gz_path = os.path.join(new_dir, gz_file)\n",
    "            if gz_file.endswith('.tar.gz'):\n",
    "                extract_tar_gz(new_gz_path, new_dir)\n",
    "            else:\n",
    "                extract_gz(new_gz_path, new_dir)\n",
    "\n",
    "\n",
    "def extract_all():\n",
    "    for subdir in os.listdir(ARTICLES_PATH):\n",
    "        subdir_path = os.path.join(ARTICLES_PATH, subdir)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            process_subdir(subdir_path)\n",
    "\n",
    "\n",
    "extract_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean():\n",
    "    for root, dirs, files in os.walk(ARTICLES_PATH):\n",
    "        for file in files:\n",
    "            if file.endswith('.gz'):\n",
    "                os.remove(os.path.join(root, file))\n",
    "\n",
    "\n",
    "clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class Category(Enum):\n",
    "    AC = 'commutative_algebra'\n",
    "    AG = 'algebraic_geometry'\n",
    "    AP = 'analysis_of_pdes'\n",
    "    AT = 'algebraic_topology'\n",
    "    CA = 'classical_analysis_and_odes'\n",
    "    CO = 'combinatorics'\n",
    "    CT = 'category_theory'\n",
    "    CV = 'complex_variables'\n",
    "    DG = 'differential_geometry'\n",
    "    DS = 'dynamical_systems'\n",
    "    FA = 'functional_analysis'\n",
    "    GM = 'general_mathematics'\n",
    "    GN = 'general_topology'\n",
    "    GR = 'group_theory'\n",
    "    GT = 'geometric_topology'\n",
    "    HO = 'history_and_overview'\n",
    "    IT = 'information_theory'\n",
    "    KT = 'k_theory_and_homology'\n",
    "    LO = 'logic'\n",
    "    MG = 'metric_geometry'\n",
    "    MP = 'mathematical_physics'\n",
    "    NA = 'numerical_analysis'\n",
    "    NT = 'number_theory'\n",
    "    OA = 'operator_algebras'\n",
    "    OC = 'optimization_and_control'\n",
    "    PR = 'probability'\n",
    "    QA = 'quantum_algebra'\n",
    "    RA = 'rings_and_algebras'\n",
    "    RT = 'representation_theory'\n",
    "    SG = 'symplectic_geometry'\n",
    "    SP = 'spectral_theory'\n",
    "    ST = 'statistics_theory'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylatexenc.macrospec import ParsedMacroArgs\n",
    "\n",
    "\n",
    "def find_file_imports(root: LatexNode):\n",
    "    stack = [iter([root])]\n",
    "    stack_end = object()\n",
    "\n",
    "    while stack:\n",
    "        node = next(stack[-1], stack_end)\n",
    "\n",
    "        if node is stack_end:\n",
    "            stack.pop()\n",
    "            continue\n",
    "\n",
    "        if isinstance(node, LatexCharsNode):\n",
    "            pass\n",
    "\n",
    "        elif isinstance(node, LatexMathNode):\n",
    "            pass\n",
    "\n",
    "        elif isinstance(node, LatexCommentNode):\n",
    "            pass\n",
    "\n",
    "        elif isinstance(node, LatexSpecialsNode):\n",
    "            pass\n",
    "\n",
    "        elif isinstance(node, LatexMacroNode):\n",
    "            if node.macroname == 'input':\n",
    "                args: ParsedMacroArgs = node.nodeargd\n",
    "                group_node: LatexGroupNode = args.argnlist[0]\n",
    "                chars_node: LatexCharsNode = group_node.nodelist[0]\n",
    "                print(chars_node.chars)\n",
    "\n",
    "            elif node.macroname == 'include':\n",
    "                pass\n",
    "\n",
    "        elif isinstance(node, LatexEnvironmentNode):\n",
    "            stack.append(iter(node.nodelist))\n",
    "\n",
    "        elif isinstance(node, LatexGroupNode):\n",
    "            stack.append(iter(node.nodelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sections/introduction\n",
      "sections/background\n",
      "sections/error\n",
      "sections/universal\n",
      "sections/conclusion\n"
     ]
    }
   ],
   "source": [
    "# NOTE merge\n",
    "path = f'{ARTICLES_PATH}/ct/2502.13810v1/main.tex'\n",
    "\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    latex = file.read()\n",
    "\n",
    "walker = LatexWalker(latex)\n",
    "nodes, pos, len_ = walker.get_latex_nodes()\n",
    "\n",
    "doc_env_node = None\n",
    "\n",
    "for node in nodes:\n",
    "    if isinstance(node, LatexEnvironmentNode) and node.environmentname == 'document':\n",
    "        doc_env_node = node\n",
    "        break\n",
    "\n",
    "if doc_env_node is not None:\n",
    "    find_file_imports(doc_env_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse(root: LatexNode):\n",
    "    stack = [iter([root])]\n",
    "    stack_end = object()\n",
    "\n",
    "    while stack:\n",
    "        node = next(stack[-1], stack_end)\n",
    "\n",
    "        if node is stack_end:\n",
    "            stack.pop()\n",
    "            continue\n",
    "\n",
    "        if isinstance(node, LatexCharsNode):\n",
    "            pass\n",
    "\n",
    "        elif isinstance(node, LatexMathNode):\n",
    "            pass\n",
    "\n",
    "        elif isinstance(node, LatexCommentNode):\n",
    "            pass\n",
    "\n",
    "        elif isinstance(node, LatexSpecialsNode):\n",
    "            pass\n",
    "\n",
    "        elif isinstance(node, LatexMacroNode):\n",
    "            pass\n",
    "\n",
    "        elif isinstance(node, LatexEnvironmentNode):\n",
    "            stack.append(iter(node.nodelist))\n",
    "\n",
    "        elif isinstance(node, LatexGroupNode):\n",
    "            stack.append(iter(node.nodelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latex_math_nodes(root: LatexNode):\n",
    "    latex_math_nodes = []\n",
    "    stack = [iter([root])]\n",
    "    stack_end = object()\n",
    "\n",
    "    while stack:\n",
    "        node = next(stack[-1], stack_end)\n",
    "\n",
    "        if node is stack_end:\n",
    "            stack.pop()\n",
    "            continue\n",
    "\n",
    "        elif isinstance(node, LatexMathNode):\n",
    "            latex_math_nodes.append(node)\n",
    "\n",
    "        elif isinstance(node, LatexEnvironmentNode):\n",
    "            stack.append(iter(node.nodelist))\n",
    "\n",
    "        elif isinstance(node, LatexGroupNode):\n",
    "            stack.append(iter(node.nodelist))\n",
    "\n",
    "    return latex_math_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def find_tex_files(dir: str) -> list[LatexMathNode]:\n",
    "    latex_math_nodes = []\n",
    "\n",
    "    for file_path in Path(dir).rglob('*.tex'):\n",
    "        for encoding in ('utf-8', 'latin1', 'cp1252'):\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding=encoding) as file:\n",
    "                    latex = file.read()\n",
    "\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "\n",
    "        walker = LatexWalker(latex)\n",
    "        nodes, _, _ = walker.get_latex_nodes()\n",
    "\n",
    "        doc_env_node = None\n",
    "\n",
    "        for node in nodes:\n",
    "            if (\n",
    "                isinstance(node, LatexEnvironmentNode)\n",
    "                and node.environmentname == 'document'\n",
    "            ):\n",
    "                doc_env_node = node\n",
    "                break\n",
    "\n",
    "        if doc_env_node is not None:\n",
    "            latex_math_nodes += get_latex_math_nodes(doc_env_node)\n",
    "\n",
    "    return latex_math_nodes\n",
    "\n",
    "\n",
    "latex_math_nodes = find_tex_files(ARTICLES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107825"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(latex_math_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_latex(latex_str: str):\n",
    "    fixed = latex_str.replace('\\\\[', '$$').replace('\\\\]', '$$')\n",
    "    fixed = fixed.replace('\\\\EE', '\\\\mathbb{E}')\n",
    "    fixed = fixed.replace('\\\\II', '\\\\mathbb{I}')\n",
    "    fixed = fixed.replace('\\\\Var', '\\\\mathrm{Var}')\n",
    "    fixed = fixed.replace('\\\\HH', '\\\\mathbb{H}')\n",
    "    fixed = fixed.replace('\\\\AND', '\\\\wedge')\n",
    "    fixed = fixed.replace('\\\\OR', '\\\\vee')\n",
    "    fixed = fixed.replace('\\\\mathbbm{1}', '\\\\mathbf{1}')\n",
    "    fixed = fixed.replace('\\\\Maj', '\\\\mathrm{Maj}')\n",
    "    fixed = fixed.replace('\\\\sgn', '\\\\operatorname{sgn}')\n",
    "    fixed = fixed.replace('\\\\Tribus', '\\\\mathrm{Tribus}')\n",
    "    fixed = fixed.replace('\\\\linebreak', '\\\\text{ }')\n",
    "    fixed = fixed.replace('\\\\Prob', '\\\\mathbb{P}')\n",
    "    fixed = fixed.replace('\\\\WW', '\\\\mathcal{W}')\n",
    "\n",
    "    return fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Math, display\n",
    "\n",
    "\n",
    "for i, latex_math_node in enumerate(latex_math_nodes[:100]):\n",
    "    latex = latex_math_node.latex_verbatim()\n",
    "    latex_fixed = fix_latex(latex)\n",
    "    math_display_object = Math(latex_fixed)\n",
    "\n",
    "    # print(i)\n",
    "    # print(math_display_object._repr_latex_())\n",
    "\n",
    "    display(math_display_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'assets/input.tex'\n",
    "\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    latex = file.read()\n",
    "\n",
    "walker = LatexWalker(latex)\n",
    "\n",
    "nodes, pos, len_ = walker.get_latex_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_env_node = None\n",
    "\n",
    "for node in nodes:\n",
    "    if isinstance(node, LatexEnvironmentNode) and node.environmentname == 'document':\n",
    "        doc_env_node = node\n",
    "        break\n",
    "\n",
    "if doc_env_node is not None:\n",
    "    extracted_text = parse_node(doc_env_node)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math-rag-jXkTH_HH-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
