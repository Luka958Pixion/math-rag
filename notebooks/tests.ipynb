{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TYPE_CHECKING\n",
    "\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from math_rag.application.containers import ApplicationContainer\n",
    "    from math_rag.infrastructure.containers import InfrastructureContainer\n",
    "\n",
    "    application_container: ApplicationContainer\n",
    "    infrastructure_container: InfrastructureContainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-21 18:11:10,932 - INFO - PyTorch version 2.6.0 available.\n"
     ]
    }
   ],
   "source": [
    "RESET = False\n",
    "%load_ext hooks.notebook_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "importer_service = application_container.math_expression_label_task_importer_service()\n",
    "exporter_service = application_container.math_expression_label_exporter_service()\n",
    "\n",
    "result_repository = infrastructure_container.math_expression_dataset_test_result_repository()\n",
    "label_repository = infrastructure_container.math_expression_label_repository()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import UUID\n",
    "\n",
    "\n",
    "dataset_id = UUID('7cdbb987-0994-4d59-8d9c-5e827e000769')\n",
    "split_name = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8eba02b2ab44d69dedc9b08e657fea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.04k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b7a1b573af4b1293ed237c85098d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/6.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2056b06c214c5bb3f7a1fb66777b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validate-00000-of-00001.parquet:   0%|          | 0.00/6.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7da3251b54841e8b60af1e088e68b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/24.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06940216e83b452eb88abab22a812fea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/27 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "defd3c15b6de4e668f34a109a3d61d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validate split:   0%|          | 0/27 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c47be93b9af4f7d8db46bfb87adcc68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/221 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-21 13:46:32,476 - INFO - Project math_expression_label_task | 7cdbb987 | test created\n",
      "2025-06-21 13:46:32,531 - INFO - Imported 221 tasks into math_expression_label_task | 7cdbb987 | test\n"
     ]
    }
   ],
   "source": [
    "project_id = await importer_service.import_tasks(None, dataset_id=dataset_id, split_name=split_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'math_rag.application.models.assistants.base.BaseAssistantOutput'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m infrastructure_container\u001b[38;5;241m.\u001b[39mllm_failed_request_repository()\u001b[38;5;241m.\u001b[39mfind_many()\n",
      "File \u001b[0;32m/workspaces/math_rag/infrastructure/repositories/documents/document_repository.py:100\u001b[0m, in \u001b[0;36mDocumentRepository.find_many\u001b[0;34m(self, filter)\u001b[0m\n\u001b[1;32m     97\u001b[0m bson_docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[1;32m     99\u001b[0m docs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_cls\u001b[38;5;241m.\u001b[39mmodel_validate(bson_doc) \u001b[38;5;28;01mfor\u001b[39;00m bson_doc \u001b[38;5;129;01min\u001b[39;00m bson_docs]\n\u001b[0;32m--> 100\u001b[0m items \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapping_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m items\n",
      "File \u001b[0;32m/workspaces/math_rag/infrastructure/mappings/documents/llm_failed_request_mapping.py:20\u001b[0m, in \u001b[0;36mLLMFailedRequestMapping.to_source\u001b[0;34m(target)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_source\u001b[39m(target: LLMFailedRequestDocument) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMFailedRequest:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LLMFailedRequest(\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mtarget\u001b[38;5;241m.\u001b[39mid,\n\u001b[0;32m---> 20\u001b[0m         request\u001b[38;5;241m=\u001b[39m\u001b[43mLLMRequestMapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mLLMResponseType\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     21\u001b[0m         errors\u001b[38;5;241m=\u001b[39mtarget\u001b[38;5;241m.\u001b[39merrors,\n\u001b[1;32m     22\u001b[0m     )\n",
      "File \u001b[0;32m/workspaces/math_rag/infrastructure/mappings/documents/llm_request_mapping.py:22\u001b[0m, in \u001b[0;36mLLMRequestMapping.to_source\u001b[0;34m(target)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_source\u001b[39m(target: LLMRequestDocument) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMRequest[LLMResponseType]:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LLMRequest(\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mtarget\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m     21\u001b[0m         conversation\u001b[38;5;241m=\u001b[39mLLMConversationMapping\u001b[38;5;241m.\u001b[39mto_source(target\u001b[38;5;241m.\u001b[39mconversation),\n\u001b[0;32m---> 22\u001b[0m         params\u001b[38;5;241m=\u001b[39m\u001b[43mLLMParamsMapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mLLMResponseType\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     23\u001b[0m         router_params\u001b[38;5;241m=\u001b[39mLLMRouterParamsMapping\u001b[38;5;241m.\u001b[39mto_source(target\u001b[38;5;241m.\u001b[39mrouter_params),\n\u001b[1;32m     24\u001b[0m     )\n",
      "File \u001b[0;32m/workspaces/math_rag/infrastructure/mappings/documents/llm_params_mapping.py:24\u001b[0m, in \u001b[0;36mLLMParamsMapping.to_source\u001b[0;34m(target)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_source\u001b[39m(target: LLMParamsDocument) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMParams[LLMResponseType]:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LLMParams[LLMResponseType](\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mtarget\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m     17\u001b[0m         model\u001b[38;5;241m=\u001b[39mtarget\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m     18\u001b[0m         temperature\u001b[38;5;241m=\u001b[39mtarget\u001b[38;5;241m.\u001b[39mtemperature,\n\u001b[1;32m     19\u001b[0m         logprobs\u001b[38;5;241m=\u001b[39mtarget\u001b[38;5;241m.\u001b[39mlogprobs,\n\u001b[1;32m     20\u001b[0m         top_logprobs\u001b[38;5;241m=\u001b[39mtarget\u001b[38;5;241m.\u001b[39mtop_logprobs,\n\u001b[1;32m     21\u001b[0m         top_p\u001b[38;5;241m=\u001b[39mtarget\u001b[38;5;241m.\u001b[39mtop_p,\n\u001b[1;32m     22\u001b[0m         reasoning_effort\u001b[38;5;241m=\u001b[39mtarget\u001b[38;5;241m.\u001b[39mreasoning_effort,\n\u001b[1;32m     23\u001b[0m         max_completion_tokens\u001b[38;5;241m=\u001b[39mtarget\u001b[38;5;241m.\u001b[39mmax_completion_tokens,\n\u001b[0;32m---> 24\u001b[0m         response_type\u001b[38;5;241m=\u001b[39m\u001b[43mTypeUtil\u001b[49m\u001b[43m[\u001b[49m\u001b[43mLLMResponseType\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_fqn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse_type\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     25\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mtarget\u001b[38;5;241m.\u001b[39mmetadata,\n\u001b[1;32m     26\u001b[0m         store\u001b[38;5;241m=\u001b[39mtarget\u001b[38;5;241m.\u001b[39mstore,\n\u001b[1;32m     27\u001b[0m         n\u001b[38;5;241m=\u001b[39mtarget\u001b[38;5;241m.\u001b[39mn,\n\u001b[1;32m     28\u001b[0m     )\n",
      "File \u001b[0;32m/workspaces/math_rag/shared/utils/type_util.py:47\u001b[0m, in \u001b[0;36mTypeUtil.from_fqn\u001b[0;34m(fqn)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(parts), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     46\u001b[0m     module_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(parts[:i])\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     module \u001b[38;5;241m=\u001b[39m import_module(module_name)\n",
      "File \u001b[0;32m<frozen importlib.util>:91\u001b[0m, in \u001b[0;36mfind_spec\u001b[0;34m(name, package)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'math_rag.application.models.assistants.base.BaseAssistantOutput'"
     ]
    }
   ],
   "source": [
    "await infrastructure_container.llm_failed_request_repository().find_many()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "math_rag.application.models.assistants.base.base_assistant_output.BaseAssistantOutput.bind.<locals>.BoundAssistantOutput"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "from math_rag.application.models.assistants import KatexCorrectorAssistantOutput\n",
    "\n",
    "\n",
    "output = KatexCorrectorAssistantOutput.bind(uuid4())\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_labels = await label_repository.find_many(\n",
    "    filter=dict(math_expression_dataset_id=dataset_id, math_expression_id=data)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_labels = await exporter_service.export(project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = await result_repository.find_many(\n",
    "    filter=dict(\n",
    "        math_expression_dataset_id=dataset_id, math_expression_dataset_split_name=split_name\n",
    "    )\n",
    ")\n",
    "\n",
    "# llama_labels = results[0].math_expression_labels\n",
    "# gpt_4_1_labels = results[1].math_expression_labels\n",
    "gpt_4_1_mini_labels = results[0].math_expression_labels\n",
    "gpt_4_1_labels = results[1].math_expression_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from math_rag.core.enums import MathExpressionLabelEnum\n",
    "from math_rag.core.models import MathExpressionLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sort_by_math_expression_id(labels: list[MathExpressionLabel]) -> list[MathExpressionLabel]:\n",
    "    return sorted(\n",
    "        labels,\n",
    "        key=lambda label: label.math_expression_id,\n",
    "    )\n",
    "\n",
    "\n",
    "def prepare(math_expression_labels: list[MathExpressionLabel]) -> list[str]:\n",
    "    sorted = _sort_by_math_expression_id(math_expression_labels)\n",
    "\n",
    "    return [label.value.value for label in sorted]\n",
    "\n",
    "\n",
    "def evaluate_multiclass_labels(\n",
    "    y_true: list[str],\n",
    "    y_pred: list[str],\n",
    "    labels: list[str],\n",
    "):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    report = classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        labels=labels,\n",
    "        target_names=labels,\n",
    "        zero_division=0,\n",
    "    )\n",
    "    cm = confusion_matrix(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        labels=labels,\n",
    "    )\n",
    "\n",
    "    print(acc)\n",
    "    print(report)\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [e.value for e in MathExpressionLabelEnum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8235294117647058\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    equality       1.00      1.00      1.00        42\n",
      "  inequality       1.00      1.00      1.00         7\n",
      "    constant       0.32      1.00      0.49        17\n",
      "    variable       1.00      0.86      0.93        22\n",
      "       other       0.97      0.73      0.83       133\n",
      "\n",
      "    accuracy                           0.82       221\n",
      "   macro avg       0.86      0.92      0.85       221\n",
      "weighted avg       0.93      0.82      0.85       221\n",
      "\n",
      "[[42  0  0  0  0]\n",
      " [ 0  7  0  0  0]\n",
      " [ 0  0 17  0  0]\n",
      " [ 0  0  0 19  3]\n",
      " [ 0  0 36  0 97]]\n"
     ]
    }
   ],
   "source": [
    "y_true = prepare(human_labels)\n",
    "y_pred = prepare(gpt_4_1_labels)\n",
    "\n",
    "evaluate_multiclass_labels(y_true, y_pred, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_container.katex_corrector_assistant"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
