{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f32ba622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TYPE_CHECKING\n",
    "\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from math_rag.application.containers import ApplicationContainer\n",
    "    from math_rag.infrastructure.containers import InfrastructureContainer\n",
    "\n",
    "    application_container: ApplicationContainer\n",
    "    infrastructure_container: InfrastructureContainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c020d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 20:54:19,085 - INFO - datasets - config.py:54 - PyTorch version 2.6.0 available.\n"
     ]
    }
   ],
   "source": [
    "RESET = False\n",
    "%load_ext hooks.notebook_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb39d1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "google_drive_repository = infrastructure_container.google_drive_repository()\n",
    "math_article_parser_service = infrastructure_container.math_article_parser_service()\n",
    "\n",
    "file_id = google_drive_repository.get_file_id(\n",
    "    Path('ml/lectures/L07-LogisticRegression2/2024_08_10_2174b40686820b4cb591g.tex')\n",
    ")\n",
    "\n",
    "if not file_id:\n",
    "    raise ValueError()\n",
    "\n",
    "file_content = google_drive_repository.get_file_by_id(file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aad9ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math_rag.core.models import MathArticle, MathExpression\n",
    "\n",
    "\n",
    "math_article = MathArticle(\n",
    "    math_expression_dataset_id=None,\n",
    "    index_id=None,\n",
    "    name='article',\n",
    "    bytes=file_content.getvalue(),\n",
    ")\n",
    "math_nodes_, _, template = math_article_parser_service.parse_for_index(math_article)\n",
    "math_expressions: list[MathExpression] = ...  # NOTE obtained from math_nodes_\n",
    "index_to_katex = {i: math_expression.katex for i, math_expression in enumerate(math_expressions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e5d8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math_rag.infrastructure.utils import TemplateContextChunkerUtil, TemplateFormatterUtil\n",
    "\n",
    "\n",
    "template_chunks = TemplateContextChunkerUtil.chunk(template, max_context_size=1000)\n",
    "chunks = [\n",
    "    TemplateFormatterUtil.format(chunk, index_to_katex, omit_wrapper=False)\n",
    "    for chunk in template_chunks\n",
    "]\n",
    "\n",
    "# TODO send to llm\n",
    "# 1. MathExpressionDescriptionWriter\n",
    "# 2. MathExpressionDescriptionRefiner\n",
    "# 3. MathExpressionLinker?? -> checks whether 2 descriptions are actually the same (embedding clustering before)\n",
    "#\n",
    "\n",
    "\n",
    "class MathExpressionDescription:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af619704",
   "metadata": {},
   "outputs": [],
   "source": [
    "_SYSTEM_PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert math-expression description writer.\n",
    "\n",
    "Your task is to produce a precise, self-contained description of a target mathematical expression, based strictly on the surrounding context.\n",
    "\n",
    "### Instructions:\n",
    "- Be concise and unambiguous.\n",
    "- Only describe what can be inferred from the given context.\n",
    "- Avoid introducing any external assumptions or definitions.\n",
    "\"\"\"\n",
    "\n",
    "_USER_PROMPT_TEMPLATE = \"\"\"\n",
    "### Math expression of interest:\n",
    "{katex}\n",
    "\n",
    "### Math expression with surrounding context:\n",
    "{context}\n",
    "\n",
    "### Description:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ecbcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "_SYSTEM_PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert at optimizing text descriptions for vector-search embedding.\n",
    "\n",
    "Your task is to refine a provided description by removing all non-essential phrasing and meta commentary, while preserving every factual detail exactly as given.\n",
    "\n",
    "### Instructions:\n",
    "- Eliminate filler language and introductory or self-referential statements (e.g., “This description…”).\n",
    "- Retain all information and nuance present in the input.\n",
    "- Produce a concise, information-dense output optimized for embedding and retrieval.\n",
    "\"\"\"\n",
    "\n",
    "_USER_PROMPT_TEMPLATE = \"\"\"\n",
    "### Original description:\n",
    "{description}\n",
    "\n",
    "### Optimized description:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6504364",
   "metadata": {},
   "outputs": [],
   "source": [
    "_SYSTEM_PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert math-expression comparator.\n",
    "\n",
    "Your task is to decide whether two given mathematical expressions represent exactly the same entity, based solely on their surrounding contexts.\n",
    "\n",
    "### Instructions:\n",
    "- Rely only on information inferable from the two contexts.\n",
    "- Determine exact equivalence: return true if and only if they are the same entity.\n",
    "- Provide a concise reason justifying your decision.\n",
    "- Do not introduce external assumptions or definitions.\n",
    "- Output must be valid JSON with keys \"identical\" (boolean) and \"reason\" (string).\n",
    "\"\"\"\n",
    "\n",
    "_USER_PROMPT_TEMPLATE = \"\"\"\n",
    "### First math expression:\n",
    "{katex1}\n",
    "\n",
    "### Context for first expression:\n",
    "{context1}\n",
    "\n",
    "### Second math expression:\n",
    "{katex2}\n",
    "\n",
    "### Context for second expression:\n",
    "{context2}\n",
    "\n",
    "### Decision (JSON):\n",
    "{\n",
    "  \"identical\": <true/false>,\n",
    "  \"reason\": \"<your explanation here>\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1162071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_SYSTEM_PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert math-expression relationship detector.\n",
    "\n",
    "Your task is to examine indexed mathematical expressions in a context and identify which earlier expressions share a direct relationship with the expression at a specified target index.\n",
    "\n",
    "### Instructions:\n",
    "- The context lists expressions in the form `[<LaTeX> | index]`.\n",
    "- A `target` index will be provided in the user prompt.\n",
    "- For each index i < target, compare expression i with the expression at the target index.\n",
    "- If the context explicitly indicates a relationship between expression i and the target expression, include i in the output list.\n",
    "- Do not infer any connections beyond what the context directly supports.\n",
    "- Output must be valid JSON: a list of integers representing the connected indexes.\n",
    "\"\"\"\n",
    "\n",
    "_USER_PROMPT_TEMPLATE = \"\"\"\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### Target index:\n",
    "{index}\n",
    "\n",
    "### Output (JSON):\n",
    "[ /* list of indexes connected to {index} */ ]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abced44",
   "metadata": {},
   "outputs": [],
   "source": [
    "_SYSTEM_PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert math‐expression relationship describer.\n",
    "\n",
    "Your task is to write a concise, precise description of the relationship between two mathematical expressions identified by their indexes in a given context.\n",
    "\n",
    "### Instructions:\n",
    "- The context lists expressions in the form `[<LaTeX> | index]`.\n",
    "- You will be provided:\n",
    "  - a `source` index\n",
    "  - a `target` index\n",
    "- Locate the corresponding expressions in the context.\n",
    "- Describe the relationship between the source expression and the target expression, based strictly on the context.\n",
    "- Be precise and unambiguous.\n",
    "- Do not introduce any external assumptions or definitions.\n",
    "\"\"\"\n",
    "\n",
    "_USER_PROMPT_TEMPLATE = \"\"\"\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### Source index:\n",
    "{source}\n",
    "\n",
    "### Target index:\n",
    "{target}\n",
    "\n",
    "### Relationship description:\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
