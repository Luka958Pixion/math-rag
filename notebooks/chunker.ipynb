{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "500b0bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcce5a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a823c915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 08:37:27,596 - INFO - PyTorch version 2.6.0 available.\n"
     ]
    }
   ],
   "source": [
    "from math_rag.infrastructure.containers import InfrastructureContainer\n",
    "\n",
    "\n",
    "RESET = True\n",
    "\n",
    "# containers\n",
    "infrastructure_container = InfrastructureContainer()\n",
    "infrastructure_container.init_resources()\n",
    "infrastructure_container.wire(modules=[__name__])\n",
    "\n",
    "application_container = infrastructure_container.application_container()\n",
    "application_container.init_resources()\n",
    "application_container.wire(modules=[__name__])\n",
    "\n",
    "# seed\n",
    "for object_seeder in infrastructure_container.object_seeders():\n",
    "    object_seeder.seed(reset=RESET)\n",
    "\n",
    "for document_seeder in infrastructure_container.document_seeders():\n",
    "    await document_seeder.seed(reset=RESET)\n",
    "\n",
    "# index\n",
    "for document_indexer in infrastructure_container.document_indexers():\n",
    "    await document_indexer.index(reset=RESET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e59340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "google_drive_repository = infrastructure_container.google_drive_repository()\n",
    "\n",
    "file_id = google_drive_repository.get_file_id(\n",
    "    Path('ml/lectures/L07-LogisticRegression2/2024_08_10_2174b40686820b4cb591g.tex')\n",
    ")\n",
    "\n",
    "if not file_id:\n",
    "    raise ValueError()\n",
    "\n",
    "file_content = google_drive_repository.get_file_by_id(file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c589e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "latex = file_content.getvalue().decode()\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b3e4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_parser_service = infrastructure_container.latex_parser_service()\n",
    "latex_node_walker_service = infrastructure_container.latex_node_walker_service()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "081fadcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text = latex_to_plain_text(latex)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb45916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage: template.format(**your_dynamic_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac21333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math_rag.core.models import MathExpression\n",
    "\n",
    "\n",
    "index_id = ...\n",
    "math_article_id = ...\n",
    "\n",
    "latex = ...\n",
    "katex = ...\n",
    "position = ...\n",
    "is_inline = ...\n",
    "\n",
    "math_expression = MathExpression(\n",
    "    math_article_id=...,\n",
    "    math_expression_dataset_id=None,\n",
    "    index_id=index_id,\n",
    "    latex=latex,\n",
    "    katex=katex,\n",
    "    position=position,\n",
    "    is_inline=is_inline,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6fab77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 39]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "text = 'This is [math_placeholder] and another [math_placeholder] here.'\n",
    "\n",
    "pattern = r'\\[math_placeholder\\]'\n",
    "positions = [match.start() for match in re.finditer(pattern, text)]\n",
    "\n",
    "print(positions)  # Output: [8, 33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ec4f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(\n",
    "    text: str, positions: list[int], lengths: list[int], max_window_size: int = 200\n",
    ") -> list[str]:\n",
    "    n = len(positions)\n",
    "    chunks: list[str] = []\n",
    "\n",
    "    # 1) build the first window\n",
    "    # if the very first entity is by itself too long, it can never be chunked\n",
    "    first_len = lengths[0]\n",
    "\n",
    "    if first_len > max_window_size:\n",
    "        raise ValueError(\n",
    "            f'Entity at position {positions[0]} '\n",
    "            f'has length {first_len}, which exceeds '\n",
    "            f'the maximum window size of {max_window_size} characters'\n",
    "        )\n",
    "\n",
    "    start_index = 0\n",
    "    end_index = 0\n",
    "\n",
    "    # greedily expand until adding the next entity would overflow\n",
    "    while end_index < n:\n",
    "        entity_end = positions[end_index] + lengths[end_index]\n",
    "\n",
    "        if entity_end <= max_window_size:\n",
    "            end_index += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Emit the first chunk\n",
    "    first_end = positions[end_index - 1] + lengths[end_index - 1]\n",
    "    chunks.append(text[:first_end])\n",
    "\n",
    "    # 2) slide the window over each subsequent entity\n",
    "    for current_index in range(end_index, n):\n",
    "        new_start = positions[current_index]\n",
    "        last_end = positions[current_index - 1] + lengths[current_index - 1]\n",
    "\n",
    "        # gap check\n",
    "        gap = new_start - last_end\n",
    "\n",
    "        if gap > max_window_size:\n",
    "            raise ValueError(\n",
    "                f'Gap of {gap} characters between entity ending at {last_end} '\n",
    "                f'and next entity at {new_start} exceeds '\n",
    "                f'the maximum window size of {max_window_size} characters'\n",
    "            )\n",
    "\n",
    "        # slide off old entities until the new one fits\n",
    "        while start_index < current_index:\n",
    "            window_start = positions[start_index] if start_index > 0 else 0\n",
    "            candidate_end = new_start + lengths[current_index]\n",
    "\n",
    "            if candidate_end - window_start <= max_window_size:\n",
    "                break\n",
    "            start_index += 1\n",
    "\n",
    "        window_start = positions[start_index] if start_index > 0 else 0\n",
    "        chunks.append(text[window_start : new_start + lengths[current_index]])\n",
    "\n",
    "    return chunks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
