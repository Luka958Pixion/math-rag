{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config\n",
    "from huggingface_hub import AsyncInferenceClient\n",
    "\n",
    "\n",
    "HUGGINGFACE_TOKEN = config('HUGGINGFACE_TOKEN')\n",
    "\n",
    "TGI_BASE_URL = ''\n",
    "MODEL_HUB_ID = 'microsoft/Phi-3-mini-4k-instruct'\n",
    "\n",
    "client = AsyncInferenceClient(\n",
    "    # base_url=TGI_BASE_URL,\n",
    "    model=MODEL_HUB_ID,\n",
    "    provider='hf-inference',\n",
    "    timeout=None,\n",
    "    api_key=HUGGINGFACE_TOKEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math_rag.application.base.assistants import BaseAssistantInput, BaseAssistantOutput\n",
    "\n",
    "\n",
    "class SomeInput(BaseAssistantInput):\n",
    "    pass\n",
    "\n",
    "\n",
    "class SomeOutput(BaseAssistantOutput):\n",
    "    result: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from math_rag.application.models.inference import (\n",
    "    LLMBatchRequest,\n",
    "    LLMBatchResult,\n",
    "    LLMConversation,\n",
    "    LLMMessage,\n",
    "    LLMParams,\n",
    "    LLMRequest,\n",
    ")\n",
    "from math_rag.infrastructure.mappings.inference.huggingface import (\n",
    "    LLMRequestMapping,\n",
    "    LLMResponseListMapping,\n",
    ")\n",
    "\n",
    "\n",
    "MODEL_HUB_ID = 'microsoft/Phi-3-mini-4k-instruct'\n",
    "some_input = SomeInput()\n",
    "\n",
    "request = LLMRequest(\n",
    "    conversation=LLMConversation(\n",
    "        messages=[\n",
    "            LLMMessage(role='system', content='You are a helpful assistant.'),\n",
    "            LLMMessage(role='user', content='what is 2+2'),\n",
    "        ]\n",
    "    ),\n",
    "    params=LLMParams(\n",
    "        model=MODEL_HUB_ID,\n",
    "        temperature=0,\n",
    "        response_type=SomeOutput,\n",
    "        max_completion_tokens=10,\n",
    "        metadata={'input_id': str(some_input.id)},\n",
    "    ),\n",
    ")\n",
    "\n",
    "batch_request: LLMBatchRequest = LLMBatchRequest(requests=[request])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests = [LLMRequestMapping.to_target(request) for request in batch_request.requests]\n",
    "lines = [json.dumps(request, separators=(',', ':')) for request in requests]\n",
    "jsonl_str = '\\n'.join(lines)\n",
    "jsonl_bytes = jsonl_str.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_dict = json.loads(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionOutput(choices=[ChatCompletionOutputComplete(finish_reason='stop', index=0, message=ChatCompletionOutputMessage(role='assistant', content='{ \"result\": 4 }', tool_call_id=None, tool_calls=None), logprobs=None)], created=1743600003, id='', model='microsoft/Phi-3-mini-4k-instruct', system_fingerprint='3.2.1-native', usage=ChatCompletionOutputUsage(completion_tokens=9, prompt_tokens=17, total_tokens=26), object='chat.completion')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = await client.chat_completion(**request_dict)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResponseList(id=UUID('f7fd3b29-2772-468d-831f-b160bf1dfaa0'), request_id=UUID('cb02d5a3-bed8-4109-b06c-04d585081ef3'), responses=[LLMResponse(id=UUID('3976268b-adbf-494a-b88b-fda24781d477'), content=BoundAssistantOutput(id=UUID('bd7fdedd-f32a-4d7f-845d-0a21413828b6'), input_id=UUID('c882baa3-2047-4f65-b8df-bd176bba3b2c'), result=4), logprobs=None)])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_list = LLMResponseListMapping.to_source(\n",
    "    result,\n",
    "    request_id=request.id,\n",
    "    input_id=request_dict['extra_body']['input_id'],\n",
    "    response_type=SomeOutput,\n",
    ")\n",
    "response_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = Path(f'.tmp/input_{batch_request.id}.jsonl')\n",
    "\n",
    "with open(input_file_path, 'w') as input_file:\n",
    "    for line in lines:\n",
    "        input_file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apptainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from math_rag.infrastructure.containers import InfrastructureContainer\n",
    "\n",
    "\n",
    "infrastructure_container = InfrastructureContainer()\n",
    "infrastructure_container.init_resources()\n",
    "\n",
    "apptainer_client = infrastructure_container.apptainer_client()\n",
    "sftp_client = infrastructure_container.sftp_client()\n",
    "pbs_pro_client = infrastructure_container.pbs_pro_client()\n",
    "hpc_client = infrastructure_container.hpc_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await apptainer_client.health()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math_rag.infrastructure.inference.huggingface import HuggingFaceBatchLLM\n",
    "\n",
    "\n",
    "# TODO\n",
    "llm = HuggingFaceBatchLLM(\n",
    "    remote_project_root=Path('tgi_default_root'),\n",
    "    hpc_client=hpc_client,\n",
    "    pbs_pro_client=pbs_pro_client,\n",
    "    sftp_client=sftp_client,\n",
    "    apptainer_client=apptainer_client,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "await llm.init_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not async_generator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m llm\u001b[38;5;241m.\u001b[39mbatch_generate(\n\u001b[1;32m      2\u001b[0m     batch_request\u001b[38;5;241m=\u001b[39mbatch_request,\n\u001b[1;32m      3\u001b[0m     response_type\u001b[38;5;241m=\u001b[39mSomeOutput,\n\u001b[1;32m      4\u001b[0m     poll_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m,\n\u001b[1;32m      5\u001b[0m     max_num_retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m res\n",
      "File \u001b[0;32m/workspaces/math_rag/infrastructure/inference/partials/partial_batch_llm.py:88\u001b[0m, in \u001b[0;36mPartialBatchLLM.batch_generate\u001b[0;34m(self, batch_request, response_type, poll_interval, max_num_retries)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_num_retries:\n\u001b[1;32m     81\u001b[0m     batch_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_generate_retry(\n\u001b[1;32m     82\u001b[0m         batch_request,\n\u001b[1;32m     83\u001b[0m         response_type,\n\u001b[1;32m     84\u001b[0m         poll_interval\u001b[38;5;241m=\u001b[39mpoll_interval,\n\u001b[1;32m     85\u001b[0m         max_num_retries\u001b[38;5;241m=\u001b[39mmax_num_retries,\n\u001b[1;32m     86\u001b[0m     )\n\u001b[0;32m---> 88\u001b[0m batch_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_generate(\n\u001b[1;32m     89\u001b[0m     batch_request, response_type, poll_interval\n\u001b[1;32m     90\u001b[0m )\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch_result\n",
      "File \u001b[0;32m/workspaces/math_rag/infrastructure/inference/partials/partial_batch_llm.py:23\u001b[0m, in \u001b[0;36mPartialBatchLLM._batch_generate\u001b[0;34m(self, batch_request, response_type, poll_interval)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_batch_generate\u001b[39m(\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     19\u001b[0m     batch_request: LLMBatchRequest[LLMResponseType],\n\u001b[1;32m     20\u001b[0m     response_type: \u001b[38;5;28mtype\u001b[39m[LLMResponseType],\n\u001b[1;32m     21\u001b[0m     poll_interval: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[1;32m     22\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMBatchResult[LLMResponseType]:\n\u001b[0;32m---> 23\u001b[0m     batch_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_generate_init(batch_request)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m         batch_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_generate_result(batch_id, response_type)\n",
      "File \u001b[0;32m/workspaces/math_rag/infrastructure/inference/huggingface/huggingface_batch_llm.py:115\u001b[0m, in \u001b[0;36mHuggingFaceBatchLLM.batch_generate_init\u001b[0;34m(self, batch_request)\u001b[0m\n\u001b[1;32m    113\u001b[0m jsonl_stream \u001b[38;5;241m=\u001b[39m BytesStreamerUtil\u001b[38;5;241m.\u001b[39mstream(jsonl_bytes)\n\u001b[1;32m    114\u001b[0m input_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremote_project_root \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msftp_client\u001b[38;5;241m.\u001b[39mupload(jsonl_stream, input_path)\n\u001b[1;32m    117\u001b[0m pbs_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtgi.sh\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    118\u001b[0m batch_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpbs_pro_client\u001b[38;5;241m.\u001b[39mqueue_submit(\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremote_project_root,\n\u001b[1;32m    120\u001b[0m     pbs_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m     walltime\u001b[38;5;241m=\u001b[39mtimedelta(minutes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m),\n\u001b[1;32m    126\u001b[0m )\n",
      "File \u001b[0;32m/workspaces/.venv/lib/python3.12/site-packages/backoff/_async.py:151\u001b[0m, in \u001b[0;36mretry_exception.<locals>.retry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m details \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m: target,\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m: args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melapsed\u001b[39m\u001b[38;5;124m\"\u001b[39m: elapsed,\n\u001b[1;32m    148\u001b[0m }\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    153\u001b[0m     giveup_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m giveup(e)\n",
      "File \u001b[0;32m/workspaces/math_rag/infrastructure/clients/sftp_client.py:46\u001b[0m, in \u001b[0;36mSFTPClient.upload\u001b[0;34m(self, source, target)\u001b[0m\n\u001b[1;32m     42\u001b[0m target_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m stack\u001b[38;5;241m.\u001b[39menter_async_context(\n\u001b[1;32m     43\u001b[0m     sftp\u001b[38;5;241m.\u001b[39mopen(target_str, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mab\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m offset \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     45\u001b[0m source_stream \u001b[38;5;241m=\u001b[39m FileStreamerUtil\u001b[38;5;241m.\u001b[39mstream(source, offset)\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m FileStreamWriterUtil\u001b[38;5;241m.\u001b[39mwrite(source_stream, target_file)\n",
      "File \u001b[0;32m/workspaces/math_rag/infrastructure/utils/file_stream_writer_util.py:19\u001b[0m, in \u001b[0;36mFileStreamWriterUtil.write\u001b[0;34m(source, target)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[38;5;28;01mawait\u001b[39;00m target_file\u001b[38;5;241m.\u001b[39mwrite(chunk)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(target, SFTPClientFile):\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m source:\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m target\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
      "File \u001b[0;32m/workspaces/math_rag/infrastructure/utils/file_streamer_util.py:14\u001b[0m, in \u001b[0;36mFileStreamerUtil.stream\u001b[0;34m(source, offset)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstream\u001b[39m(\n\u001b[1;32m     12\u001b[0m     source: Path, offset: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     13\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncGenerator[\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m source_file:\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m offset:\n\u001b[1;32m     16\u001b[0m             \u001b[38;5;28;01mawait\u001b[39;00m source_file\u001b[38;5;241m.\u001b[39mseek(offset, whence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/workspaces/.venv/lib/python3.12/site-packages/aiofiles/base.py:63\u001b[0m, in \u001b[0;36mAiofilesContextManager.__aenter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__aenter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/workspaces/.venv/lib/python3.12/site-packages/aiofiles/base.py:59\u001b[0m, in \u001b[0;36mAiofilesContextManager.__await__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__await__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coro\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__await__\u001b[39m()\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj\n",
      "File \u001b[0;32m/workspaces/.venv/lib/python3.12/site-packages/aiofiles/threadpool/__init__.py:92\u001b[0m, in \u001b[0;36m_open\u001b[0;34m(file, mode, buffering, encoding, errors, newline, closefd, opener, loop, executor)\u001b[0m\n\u001b[1;32m     80\u001b[0m     loop \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mget_running_loop()\n\u001b[1;32m     81\u001b[0m cb \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m     82\u001b[0m     sync_open,\n\u001b[1;32m     83\u001b[0m     file,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m     opener\u001b[38;5;241m=\u001b[39mopener,\n\u001b[1;32m     91\u001b[0m )\n\u001b[0;32m---> 92\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mrun_in_executor(executor, cb)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(f, loop\u001b[38;5;241m=\u001b[39mloop, executor\u001b[38;5;241m=\u001b[39mexecutor)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/asyncio/futures.py:291\u001b[0m, in \u001b[0;36mFuture.__await__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncio_future_blocking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mawait wasn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt used with future\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/asyncio/tasks.py:385\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 385\u001b[0m         \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/asyncio/futures.py:203\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not async_generator"
     ]
    }
   ],
   "source": [
    "res = await llm.batch_generate(\n",
    "    batch_request=batch_request,\n",
    "    response_type=SomeOutput,\n",
    "    poll_interval=3 * 60,\n",
    "    max_num_retries=0,\n",
    ")\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
