{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config\n",
    "from huggingface_hub import AsyncInferenceClient\n",
    "\n",
    "\n",
    "HUGGINGFACE_TOKEN = config('HUGGINGFACE_TOKEN')\n",
    "\n",
    "TGI_BASE_URL = ''\n",
    "MODEL_HUB_ID = 'microsoft/Phi-3-mini-4k-instruct'\n",
    "\n",
    "client = AsyncInferenceClient(\n",
    "    # base_url=TGI_BASE_URL,\n",
    "    model=MODEL_HUB_ID,\n",
    "    provider='hf-inference',\n",
    "    timeout=None,\n",
    "    api_key=HUGGINGFACE_TOKEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math_rag.application.base.assistants import BaseAssistantInput, BaseAssistantOutput\n",
    "\n",
    "\n",
    "class SomeInput(BaseAssistantInput):\n",
    "    pass\n",
    "\n",
    "\n",
    "class SomeOutput(BaseAssistantOutput):\n",
    "    result: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from math_rag.application.models.inference import (\n",
    "    LLMBatchRequest,\n",
    "    LLMBatchResult,\n",
    "    LLMConversation,\n",
    "    LLMMessage,\n",
    "    LLMParams,\n",
    "    LLMRequest,\n",
    ")\n",
    "from math_rag.infrastructure.mappings.inference.huggingface import (\n",
    "    LLMRequestMapping,\n",
    "    LLMResponseListMapping,\n",
    ")\n",
    "\n",
    "\n",
    "MODEL_HUB_ID = 'microsoft/Phi-3-mini-4k-instruct'\n",
    "some_input = SomeInput()\n",
    "\n",
    "request = LLMRequest(\n",
    "    conversation=LLMConversation(\n",
    "        messages=[\n",
    "            LLMMessage(role='system', content='You are a helpful assistant.'),\n",
    "            LLMMessage(role='user', content='what is 2+2'),\n",
    "        ]\n",
    "    ),\n",
    "    params=LLMParams(\n",
    "        model=MODEL_HUB_ID,\n",
    "        temperature=0,\n",
    "        response_type=SomeOutput,\n",
    "        max_completion_tokens=10,\n",
    "        metadata={'input_id': str(some_input.id)},\n",
    "    ),\n",
    ")\n",
    "\n",
    "batch_request: LLMBatchRequest = LLMBatchRequest(requests=[request])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests = [LLMRequestMapping.to_target(request) for request in batch_request.requests]\n",
    "lines = [json.dumps(request, separators=(',', ':')) for request in requests]\n",
    "jsonl_str = '\\n'.join(lines)\n",
    "jsonl_bytes = jsonl_str.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_dict = json.loads(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionOutput(choices=[ChatCompletionOutputComplete(finish_reason='stop', index=0, message=ChatCompletionOutputMessage(role='assistant', content='{ \"result\": 4 }', tool_call_id=None, tool_calls=None), logprobs=None)], created=1743600003, id='', model='microsoft/Phi-3-mini-4k-instruct', system_fingerprint='3.2.1-native', usage=ChatCompletionOutputUsage(completion_tokens=9, prompt_tokens=17, total_tokens=26), object='chat.completion')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = await client.chat_completion(**request_dict)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResponseList(id=UUID('f7fd3b29-2772-468d-831f-b160bf1dfaa0'), request_id=UUID('cb02d5a3-bed8-4109-b06c-04d585081ef3'), responses=[LLMResponse(id=UUID('3976268b-adbf-494a-b88b-fda24781d477'), content=BoundAssistantOutput(id=UUID('bd7fdedd-f32a-4d7f-845d-0a21413828b6'), input_id=UUID('c882baa3-2047-4f65-b8df-bd176bba3b2c'), result=4), logprobs=None)])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_list = LLMResponseListMapping.to_source(\n",
    "    result,\n",
    "    request_id=request.id,\n",
    "    input_id=request_dict['extra_body']['input_id'],\n",
    "    response_type=SomeOutput,\n",
    ")\n",
    "response_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = Path(f'.tmp/input_{batch_request.id}.jsonl')\n",
    "\n",
    "with open(input_file_path, 'w') as input_file:\n",
    "    for line in lines:\n",
    "        input_file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apptainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from math_rag.infrastructure.containers import InfrastructureContainer\n",
    "\n",
    "\n",
    "infrastructure_container = InfrastructureContainer()\n",
    "infrastructure_container.init_resources()\n",
    "\n",
    "apptainer_client = infrastructure_container.apptainer_client()\n",
    "sftp_client = infrastructure_container.sftp_client()\n",
    "pbs_pro_client = infrastructure_container.pbs_pro_client()\n",
    "hpc_client = infrastructure_container.hpc_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 13:59:31,131 - INFO - HTTP Request: GET http://host.docker.internal:7015/health \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await apptainer_client.health()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math_rag.infrastructure.inference.huggingface import HuggingFaceBatchLLM\n",
    "\n",
    "\n",
    "llm = HuggingFaceBatchLLM(\n",
    "    remote_project_root=Path('tgi_default_root'),\n",
    "    hpc_client=hpc_client,\n",
    "    pbs_pro_client=pbs_pro_client,\n",
    "    sftp_client=sftp_client,\n",
    "    apptainer_client=apptainer_client,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 14:10:09,700 - INFO - Host canonicalization disabled\n",
      "2025-04-08 14:10:09,700 - INFO - Opening SSH connection to login-gpu.hpc.srce.hr, port 22\n",
      "2025-04-08 14:10:09,716 - INFO - [conn=25] Connected to SSH server at login-gpu.hpc.srce.hr, port 22\n",
      "2025-04-08 14:10:09,716 - INFO - [conn=25]   Local address: 172.22.0.5, port 33310\n",
      "2025-04-08 14:10:09,716 - INFO - [conn=25]   Peer address: 161.53.2.37, port 22\n",
      "2025-04-08 14:10:09,748 - INFO - [conn=25] Beginning auth for user lpanic\n",
      "2025-04-08 14:10:10,013 - INFO - [conn=25] Auth for user lpanic succeeded\n",
      "2025-04-08 14:10:10,013 - INFO - [conn=25, chan=0] Requesting new SSH session\n",
      "2025-04-08 14:10:10,063 - INFO - [conn=25, chan=0]   Command: mkdir -p tgi_default_root\n",
      "2025-04-08 14:10:10,218 - INFO - [conn=25, chan=0] Received exit status 0\n",
      "2025-04-08 14:10:10,220 - INFO - [conn=25, chan=0] Received channel close\n",
      "2025-04-08 14:10:10,222 - INFO - [conn=25, chan=0] Channel closed\n",
      "2025-04-08 14:10:10,224 - INFO - Command `mkdir -p tgi_default_root` in `run` returned stdout: \n",
      "2025-04-08 14:10:10,224 - INFO - [conn=25] Closing connection\n",
      "2025-04-08 14:10:10,225 - INFO - [conn=25] Sending disconnect: Disconnected by application (11)\n",
      "2025-04-08 14:10:10,225 - INFO - [conn=25] Connection closed\n",
      "2025-04-08 14:10:10,226 - INFO - Host canonicalization disabled\n",
      "2025-04-08 14:10:10,226 - INFO - Opening SSH connection to login-gpu.hpc.srce.hr, port 22\n",
      "2025-04-08 14:10:10,237 - INFO - [conn=26] Connected to SSH server at login-gpu.hpc.srce.hr, port 22\n",
      "2025-04-08 14:10:10,238 - INFO - [conn=26]   Local address: 172.22.0.5, port 33322\n",
      "2025-04-08 14:10:10,238 - INFO - [conn=26]   Peer address: 161.53.2.37, port 22\n",
      "2025-04-08 14:10:10,269 - INFO - [conn=26] Beginning auth for user lpanic\n",
      "2025-04-08 14:10:10,539 - INFO - [conn=26] Auth for user lpanic succeeded\n",
      "2025-04-08 14:10:10,543 - INFO - [conn=26, chan=0] Requesting new SSH session\n",
      "2025-04-08 14:10:10,589 - INFO - [conn=26, chan=0]   Command: test -f tgi_default_root/tgi_server.def && echo \"true\" || echo \"false\"\n",
      "2025-04-08 14:10:10,743 - INFO - [conn=26, chan=0] Received exit status 0\n",
      "2025-04-08 14:10:10,745 - INFO - [conn=26, chan=0] Received channel close\n",
      "2025-04-08 14:10:10,747 - INFO - [conn=26, chan=0] Channel closed\n",
      "2025-04-08 14:10:10,749 - INFO - Command `test -f tgi_default_root/tgi_server.def && echo \"true\" || echo \"false\"` in `run` returned stdout: true\n",
      "2025-04-08 14:10:10,749 - INFO - [conn=26] Closing connection\n",
      "2025-04-08 14:10:10,750 - INFO - [conn=26] Sending disconnect: Disconnected by application (11)\n",
      "2025-04-08 14:10:10,751 - INFO - [conn=26] Connection closed\n",
      "2025-04-08 14:10:10,753 - INFO - Host canonicalization disabled\n",
      "2025-04-08 14:10:10,753 - INFO - Opening SSH connection to login-gpu.hpc.srce.hr, port 22\n",
      "2025-04-08 14:10:10,766 - INFO - [conn=27] Connected to SSH server at login-gpu.hpc.srce.hr, port 22\n",
      "2025-04-08 14:10:10,766 - INFO - [conn=27]   Local address: 172.22.0.5, port 33324\n",
      "2025-04-08 14:10:10,767 - INFO - [conn=27]   Peer address: 161.53.2.37, port 22\n",
      "2025-04-08 14:10:10,799 - INFO - [conn=27] Beginning auth for user lpanic\n",
      "2025-04-08 14:10:11,070 - INFO - [conn=27] Auth for user lpanic succeeded\n",
      "2025-04-08 14:10:11,072 - INFO - [conn=27, chan=0] Requesting new SSH session\n",
      "2025-04-08 14:10:11,119 - INFO - [conn=27, chan=0]   Command: sha256sum tgi_default_root/tgi_server.def | awk '{print $1}'\n",
      "2025-04-08 14:10:11,275 - INFO - [conn=27, chan=0] Received exit status 0\n",
      "2025-04-08 14:10:11,276 - INFO - [conn=27, chan=0] Received channel close\n",
      "2025-04-08 14:10:11,278 - INFO - [conn=27, chan=0] Channel closed\n",
      "2025-04-08 14:10:11,280 - INFO - Command `sha256sum tgi_default_root/tgi_server.def | awk '{print $1}'` in `run` returned stdout: 96daf6453602cd3cd784d18d16d87bc3bd7e6e013ee633e4f6be74f18dcbe65d\n",
      "2025-04-08 14:10:11,280 - INFO - [conn=27] Closing connection\n",
      "2025-04-08 14:10:11,281 - INFO - [conn=27] Sending disconnect: Disconnected by application (11)\n",
      "2025-04-08 14:10:11,282 - INFO - [conn=27] Connection closed\n",
      "2025-04-08 14:10:11,283 - INFO - Upload skipped: /workspaces/assets/hpc/hf/tgi/tgi_server.def unchanged\n",
      "2025-04-08 14:10:11,284 - INFO - Host canonicalization disabled\n",
      "2025-04-08 14:10:11,284 - INFO - Opening SSH connection to login-gpu.hpc.srce.hr, port 22\n",
      "2025-04-08 14:10:11,294 - INFO - [conn=28] Connected to SSH server at login-gpu.hpc.srce.hr, port 22\n",
      "2025-04-08 14:10:11,295 - INFO - [conn=28]   Local address: 172.22.0.5, port 33334\n",
      "2025-04-08 14:10:11,295 - INFO - [conn=28]   Peer address: 161.53.2.37, port 22\n",
      "2025-04-08 14:10:11,331 - INFO - [conn=28] Beginning auth for user lpanic\n",
      "2025-04-08 14:10:11,605 - INFO - [conn=28] Auth for user lpanic succeeded\n",
      "2025-04-08 14:10:11,606 - INFO - [conn=28, chan=0] Requesting new SSH session\n",
      "2025-04-08 14:10:11,652 - INFO - [conn=28, chan=0]   Command: test -f tgi_default_root/tgi_client.def && echo \"true\" || echo \"false\"\n",
      "2025-04-08 14:10:11,803 - INFO - [conn=28, chan=0] Received exit status 0\n",
      "2025-04-08 14:10:11,803 - INFO - [conn=28, chan=0] Received channel close\n",
      "2025-04-08 14:10:11,804 - INFO - [conn=28, chan=0] Channel closed\n",
      "2025-04-08 14:10:11,804 - INFO - Command `test -f tgi_default_root/tgi_client.def && echo \"true\" || echo \"false\"` in `run` returned stdout: true\n",
      "2025-04-08 14:10:11,804 - INFO - [conn=28] Closing connection\n",
      "2025-04-08 14:10:11,804 - INFO - [conn=28] Sending disconnect: Disconnected by application (11)\n",
      "2025-04-08 14:10:11,805 - INFO - [conn=28] Connection closed\n",
      "2025-04-08 14:10:11,806 - INFO - Host canonicalization disabled\n",
      "2025-04-08 14:10:11,806 - INFO - Opening SSH connection to login-gpu.hpc.srce.hr, port 22\n",
      "2025-04-08 14:10:11,816 - INFO - [conn=29] Connected to SSH server at login-gpu.hpc.srce.hr, port 22\n",
      "2025-04-08 14:10:11,816 - INFO - [conn=29]   Local address: 172.22.0.5, port 33338\n",
      "2025-04-08 14:10:11,817 - INFO - [conn=29]   Peer address: 161.53.2.37, port 22\n",
      "2025-04-08 14:10:11,847 - INFO - [conn=29] Beginning auth for user lpanic\n",
      "2025-04-08 14:10:12,116 - INFO - [conn=29] Auth for user lpanic succeeded\n",
      "2025-04-08 14:10:12,118 - INFO - [conn=29, chan=0] Requesting new SSH session\n",
      "2025-04-08 14:10:12,167 - INFO - [conn=29, chan=0]   Command: sha256sum tgi_default_root/tgi_client.def | awk '{print $1}'\n",
      "2025-04-08 14:10:12,321 - INFO - [conn=29, chan=0] Received exit status 0\n",
      "2025-04-08 14:10:12,321 - INFO - [conn=29, chan=0] Received channel close\n",
      "2025-04-08 14:10:12,321 - INFO - [conn=29, chan=0] Channel closed\n",
      "2025-04-08 14:10:12,322 - INFO - Command `sha256sum tgi_default_root/tgi_client.def | awk '{print $1}'` in `run` returned stdout: ac3b461167cbbcbc85332a0e5be2b0f56036529cf1df08e7a50c2207efc5dfb9\n",
      "2025-04-08 14:10:12,322 - INFO - [conn=29] Closing connection\n",
      "2025-04-08 14:10:12,322 - INFO - [conn=29] Sending disconnect: Disconnected by application (11)\n",
      "2025-04-08 14:10:12,322 - INFO - [conn=29] Connection closed\n",
      "2025-04-08 14:10:12,323 - INFO - Upload skipped: /workspaces/assets/hpc/hf/tgi/tgi_client.def unchanged\n",
      "2025-04-08 14:10:12,323 - INFO - Host canonicalization disabled\n",
      "2025-04-08 14:10:12,324 - INFO - Opening SSH connection to login-gpu.hpc.srce.hr, port 22\n",
      "2025-04-08 14:10:12,331 - INFO - [conn=30] Connected to SSH server at login-gpu.hpc.srce.hr, port 22\n",
      "2025-04-08 14:10:12,332 - INFO - [conn=30]   Local address: 172.22.0.5, port 33348\n",
      "2025-04-08 14:10:12,332 - INFO - [conn=30]   Peer address: 161.53.2.37, port 22\n",
      "2025-04-08 14:10:12,362 - INFO - [conn=30] Beginning auth for user lpanic\n",
      "2025-04-08 14:10:12,629 - INFO - [conn=30] Auth for user lpanic succeeded\n",
      "2025-04-08 14:10:12,632 - INFO - [conn=30, chan=0] Requesting new SSH session\n",
      "2025-04-08 14:10:12,676 - INFO - [conn=30, chan=0]   Command: test -f tgi_default_root/hf_cli.def && echo \"true\" || echo \"false\"\n",
      "2025-04-08 14:10:12,828 - INFO - [conn=30, chan=0] Received exit status 0\n",
      "2025-04-08 14:10:12,828 - INFO - [conn=30, chan=0] Received channel close\n",
      "2025-04-08 14:10:12,829 - INFO - [conn=30, chan=0] Channel closed\n",
      "2025-04-08 14:10:12,829 - INFO - Command `test -f tgi_default_root/hf_cli.def && echo \"true\" || echo \"false\"` in `run` returned stdout: true\n",
      "2025-04-08 14:10:12,829 - INFO - [conn=30] Closing connection\n",
      "2025-04-08 14:10:12,829 - INFO - [conn=30] Sending disconnect: Disconnected by application (11)\n",
      "2025-04-08 14:10:12,830 - INFO - [conn=30] Connection closed\n",
      "2025-04-08 14:10:12,831 - INFO - Host canonicalization disabled\n",
      "2025-04-08 14:10:12,831 - INFO - Opening SSH connection to login-gpu.hpc.srce.hr, port 22\n",
      "2025-04-08 14:10:12,841 - INFO - [conn=31] Connected to SSH server at login-gpu.hpc.srce.hr, port 22\n",
      "2025-04-08 14:10:12,841 - INFO - [conn=31]   Local address: 172.22.0.5, port 33364\n",
      "2025-04-08 14:10:12,842 - INFO - [conn=31]   Peer address: 161.53.2.37, port 22\n",
      "2025-04-08 14:10:12,873 - INFO - [conn=31] Beginning auth for user lpanic\n",
      "2025-04-08 14:10:13,142 - INFO - [conn=31] Auth for user lpanic succeeded\n",
      "2025-04-08 14:10:13,143 - INFO - [conn=31, chan=0] Requesting new SSH session\n",
      "2025-04-08 14:10:13,191 - INFO - [conn=31, chan=0]   Command: sha256sum tgi_default_root/hf_cli.def | awk '{print $1}'\n",
      "2025-04-08 14:10:13,344 - INFO - [conn=31, chan=0] Received exit status 0\n",
      "2025-04-08 14:10:13,344 - INFO - [conn=31, chan=0] Received channel close\n",
      "2025-04-08 14:10:13,345 - INFO - [conn=31, chan=0] Channel closed\n",
      "2025-04-08 14:10:13,345 - INFO - Command `sha256sum tgi_default_root/hf_cli.def | awk '{print $1}'` in `run` returned stdout: 280044c41c061db065016ce17e7e25d7437ae00e1879db0b5d394acd2f4e27f2\n",
      "2025-04-08 14:10:13,346 - INFO - [conn=31] Closing connection\n",
      "2025-04-08 14:10:13,346 - INFO - [conn=31] Sending disconnect: Disconnected by application (11)\n",
      "2025-04-08 14:10:13,346 - INFO - [conn=31] Connection closed\n",
      "2025-04-08 14:10:13,346 - INFO - Upload skipped: /workspaces/assets/hpc/hf/hf_cli.def unchanged\n",
      "2025-04-08 14:10:13,347 - INFO - Host canonicalization disabled\n",
      "2025-04-08 14:10:13,347 - INFO - Opening SSH connection to login-gpu.hpc.srce.hr, port 22\n",
      "2025-04-08 14:10:13,357 - INFO - [conn=32] Connected to SSH server at login-gpu.hpc.srce.hr, port 22\n",
      "2025-04-08 14:10:13,358 - INFO - [conn=32]   Local address: 172.22.0.5, port 33378\n",
      "2025-04-08 14:10:13,358 - INFO - [conn=32]   Peer address: 161.53.2.37, port 22\n",
      "2025-04-08 14:10:13,393 - INFO - [conn=32] Beginning auth for user lpanic\n",
      "2025-04-08 14:10:13,657 - INFO - [conn=32] Auth for user lpanic succeeded\n",
      "2025-04-08 14:10:13,658 - INFO - [conn=32, chan=0] Requesting new SSH session\n",
      "2025-04-08 14:10:13,703 - INFO - [conn=32, chan=0]   Command: test -f tgi_default_root/tgi.py && echo \"true\" || echo \"false\"\n",
      "2025-04-08 14:10:13,857 - INFO - [conn=32, chan=0] Received exit status 0\n",
      "2025-04-08 14:10:13,859 - INFO - [conn=32, chan=0] Received channel close\n",
      "2025-04-08 14:10:13,861 - INFO - [conn=32, chan=0] Channel closed\n",
      "2025-04-08 14:10:13,862 - INFO - Command `test -f tgi_default_root/tgi.py && echo \"true\" || echo \"false\"` in `run` returned stdout: true\n",
      "2025-04-08 14:10:13,862 - INFO - [conn=32] Closing connection\n",
      "2025-04-08 14:10:13,863 - INFO - [conn=32] Sending disconnect: Disconnected by application (11)\n",
      "2025-04-08 14:10:13,865 - INFO - [conn=32] Connection closed\n",
      "2025-04-08 14:10:13,866 - INFO - Host canonicalization disabled\n",
      "2025-04-08 14:10:13,866 - INFO - Opening SSH connection to login-gpu.hpc.srce.hr, port 22\n",
      "2025-04-08 14:10:13,880 - INFO - [conn=33] Connected to SSH server at login-gpu.hpc.srce.hr, port 22\n",
      "2025-04-08 14:10:13,880 - INFO - [conn=33]   Local address: 172.22.0.5, port 33386\n",
      "2025-04-08 14:10:13,880 - INFO - [conn=33]   Peer address: 161.53.2.37, port 22\n",
      "2025-04-08 14:10:13,913 - INFO - [conn=33] Beginning auth for user lpanic\n",
      "2025-04-08 14:10:14,184 - INFO - [conn=33] Auth for user lpanic succeeded\n",
      "2025-04-08 14:10:14,188 - INFO - [conn=33, chan=0] Requesting new SSH session\n",
      "2025-04-08 14:10:14,233 - INFO - [conn=33, chan=0]   Command: sha256sum tgi_default_root/tgi.py | awk '{print $1}'\n",
      "2025-04-08 14:10:14,386 - INFO - [conn=33, chan=0] Received exit status 0\n",
      "2025-04-08 14:10:14,386 - INFO - [conn=33, chan=0] Received channel close\n",
      "2025-04-08 14:10:14,387 - INFO - [conn=33, chan=0] Channel closed\n",
      "2025-04-08 14:10:14,387 - INFO - Command `sha256sum tgi_default_root/tgi.py | awk '{print $1}'` in `run` returned stdout: 3c5c667a05f7ad4c9377a3f47db53e37c2057345e7c8c2382dac5300901436e9\n",
      "2025-04-08 14:10:14,387 - INFO - [conn=33] Closing connection\n",
      "2025-04-08 14:10:14,387 - INFO - [conn=33] Sending disconnect: Disconnected by application (11)\n",
      "2025-04-08 14:10:14,388 - INFO - [conn=33] Connection closed\n",
      "2025-04-08 14:10:14,388 - INFO - Upload skipped: /workspaces/assets/hpc/hf/tgi/tgi.py unchanged\n",
      "2025-04-08 14:10:14,389 - INFO - Host canonicalization disabled\n",
      "2025-04-08 14:10:14,389 - INFO - Opening SSH connection to login-gpu.hpc.srce.hr, port 22\n",
      "2025-04-08 14:10:14,397 - INFO - [conn=34] Connected to SSH server at login-gpu.hpc.srce.hr, port 22\n",
      "2025-04-08 14:10:14,398 - INFO - [conn=34]   Local address: 172.22.0.5, port 47388\n",
      "2025-04-08 14:10:14,398 - INFO - [conn=34]   Peer address: 161.53.2.37, port 22\n",
      "2025-04-08 14:10:14,430 - INFO - [conn=34] Beginning auth for user lpanic\n",
      "2025-04-08 14:10:14,698 - INFO - [conn=34] Auth for user lpanic succeeded\n",
      "2025-04-08 14:10:14,698 - INFO - [conn=34, chan=0] Requesting new SSH session\n",
      "2025-04-08 14:10:14,747 - INFO - [conn=34, chan=0]   Command: test -f tgi_default_root/tgi.sh && echo \"true\" || echo \"false\"\n",
      "2025-04-08 14:10:14,898 - INFO - [conn=34, chan=0] Received exit status 0\n",
      "2025-04-08 14:10:14,899 - INFO - [conn=34, chan=0] Received channel close\n",
      "2025-04-08 14:10:14,899 - INFO - [conn=34, chan=0] Channel closed\n",
      "2025-04-08 14:10:14,900 - INFO - Command `test -f tgi_default_root/tgi.sh && echo \"true\" || echo \"false\"` in `run` returned stdout: true\n",
      "2025-04-08 14:10:14,900 - INFO - [conn=34] Closing connection\n",
      "2025-04-08 14:10:14,900 - INFO - [conn=34] Sending disconnect: Disconnected by application (11)\n",
      "2025-04-08 14:10:14,900 - INFO - [conn=34] Connection closed\n",
      "2025-04-08 14:10:14,901 - INFO - Host canonicalization disabled\n",
      "2025-04-08 14:10:14,902 - INFO - Opening SSH connection to login-gpu.hpc.srce.hr, port 22\n",
      "2025-04-08 14:10:14,910 - INFO - [conn=35] Connected to SSH server at login-gpu.hpc.srce.hr, port 22\n",
      "2025-04-08 14:10:14,911 - INFO - [conn=35]   Local address: 172.22.0.5, port 47392\n",
      "2025-04-08 14:10:14,911 - INFO - [conn=35]   Peer address: 161.53.2.37, port 22\n",
      "2025-04-08 14:10:14,943 - INFO - [conn=35] Beginning auth for user lpanic\n",
      "2025-04-08 14:10:15,209 - INFO - [conn=35] Auth for user lpanic succeeded\n",
      "2025-04-08 14:10:15,210 - INFO - [conn=35, chan=0] Requesting new SSH session\n",
      "2025-04-08 14:10:15,258 - INFO - [conn=35, chan=0]   Command: sha256sum tgi_default_root/tgi.sh | awk '{print $1}'\n",
      "2025-04-08 14:10:15,414 - INFO - [conn=35, chan=0] Received exit status 0\n",
      "2025-04-08 14:10:15,416 - INFO - [conn=35, chan=0] Received channel close\n",
      "2025-04-08 14:10:15,418 - INFO - [conn=35, chan=0] Channel closed\n",
      "2025-04-08 14:10:15,419 - INFO - Command `sha256sum tgi_default_root/tgi.sh | awk '{print $1}'` in `run` returned stdout: 0cbdfd660f22f712f8de057e715a9d0f3c5b978bfc4b96f61a68abda761bd10a\n",
      "2025-04-08 14:10:15,419 - INFO - [conn=35] Closing connection\n",
      "2025-04-08 14:10:15,420 - INFO - [conn=35] Sending disconnect: Disconnected by application (11)\n",
      "2025-04-08 14:10:15,421 - INFO - [conn=35] Connection closed\n",
      "2025-04-08 14:10:15,422 - INFO - Upload skipped: /workspaces/assets/hpc/hf/tgi/tgi.sh unchanged\n",
      "2025-04-08 14:10:15,423 - INFO - Host canonicalization disabled\n",
      "2025-04-08 14:10:15,423 - INFO - Opening SSH connection to login-gpu.hpc.srce.hr, port 22\n",
      "2025-04-08 14:10:15,435 - INFO - [conn=36] Connected to SSH server at login-gpu.hpc.srce.hr, port 22\n",
      "2025-04-08 14:10:15,435 - INFO - [conn=36]   Local address: 172.22.0.5, port 47398\n",
      "2025-04-08 14:10:15,435 - INFO - [conn=36]   Peer address: 161.53.2.37, port 22\n",
      "2025-04-08 14:10:15,468 - INFO - [conn=36] Beginning auth for user lpanic\n",
      "2025-04-08 14:10:15,743 - INFO - [conn=36] Auth for user lpanic succeeded\n",
      "2025-04-08 14:10:15,746 - INFO - [conn=36, chan=0] Requesting new SSH session\n",
      "2025-04-08 14:10:15,792 - INFO - [conn=36, chan=0]   Command: test -f tgi_default_root/.env.hpc.hf.tgi && echo \"true\" || echo \"false\"\n",
      "2025-04-08 14:10:15,944 - INFO - [conn=36, chan=0] Received exit status 0\n",
      "2025-04-08 14:10:15,946 - INFO - [conn=36, chan=0] Received channel close\n",
      "2025-04-08 14:10:15,948 - INFO - [conn=36, chan=0] Channel closed\n",
      "2025-04-08 14:10:15,949 - INFO - Command `test -f tgi_default_root/.env.hpc.hf.tgi && echo \"true\" || echo \"false\"` in `run` returned stdout: true\n",
      "2025-04-08 14:10:15,949 - INFO - [conn=36] Closing connection\n",
      "2025-04-08 14:10:15,950 - INFO - [conn=36] Sending disconnect: Disconnected by application (11)\n",
      "2025-04-08 14:10:15,951 - INFO - [conn=36] Connection closed\n",
      "2025-04-08 14:10:15,953 - INFO - Host canonicalization disabled\n",
      "2025-04-08 14:10:15,953 - INFO - Opening SSH connection to login-gpu.hpc.srce.hr, port 22\n",
      "2025-04-08 14:10:15,967 - INFO - [conn=37] Connected to SSH server at login-gpu.hpc.srce.hr, port 22\n",
      "2025-04-08 14:10:15,967 - INFO - [conn=37]   Local address: 172.22.0.5, port 47408\n",
      "2025-04-08 14:10:15,967 - INFO - [conn=37]   Peer address: 161.53.2.37, port 22\n",
      "2025-04-08 14:10:16,004 - INFO - [conn=37] Beginning auth for user lpanic\n",
      "2025-04-08 14:10:16,275 - INFO - [conn=37] Auth for user lpanic succeeded\n",
      "2025-04-08 14:10:16,277 - INFO - [conn=37, chan=0] Requesting new SSH session\n",
      "2025-04-08 14:10:16,321 - INFO - [conn=37, chan=0]   Command: sha256sum tgi_default_root/.env.hpc.hf.tgi | awk '{print $1}'\n",
      "2025-04-08 14:10:16,477 - INFO - [conn=37, chan=0] Received exit status 0\n",
      "2025-04-08 14:10:16,479 - INFO - [conn=37, chan=0] Received channel close\n",
      "2025-04-08 14:10:16,482 - INFO - [conn=37, chan=0] Channel closed\n",
      "2025-04-08 14:10:16,483 - INFO - Command `sha256sum tgi_default_root/.env.hpc.hf.tgi | awk '{print $1}'` in `run` returned stdout: 45faa668f3139d4fa720ed99845cf19bf3aaee922c8afe8b12d1f3daed5452a6\n",
      "2025-04-08 14:10:16,483 - INFO - [conn=37] Closing connection\n",
      "2025-04-08 14:10:16,483 - INFO - [conn=37] Sending disconnect: Disconnected by application (11)\n",
      "2025-04-08 14:10:16,484 - INFO - [conn=37] Connection closed\n",
      "2025-04-08 14:10:16,484 - INFO - Upload skipped: /workspaces/.env.hpc.hf.tgi unchanged\n"
     ]
    }
   ],
   "source": [
    "await llm.init_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SFTPNoSuchFile",
     "evalue": "No such file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSFTPNoSuchFile\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m llm\u001b[38;5;241m.\u001b[39mbatch_generate(\n\u001b[1;32m      2\u001b[0m     batch_request\u001b[38;5;241m=\u001b[39mbatch_request,\n\u001b[1;32m      3\u001b[0m     response_type\u001b[38;5;241m=\u001b[39mSomeOutput,\n\u001b[1;32m      4\u001b[0m     poll_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m,\n\u001b[1;32m      5\u001b[0m     max_num_retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m res\n",
      "File \u001b[0;32m/workspaces/math_rag/infrastructure/inference/partials/partial_batch_llm.py:88\u001b[0m, in \u001b[0;36mPartialBatchLLM.batch_generate\u001b[0;34m(self, batch_request, response_type, poll_interval, max_num_retries)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_num_retries:\n\u001b[1;32m     81\u001b[0m     batch_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_generate_retry(\n\u001b[1;32m     82\u001b[0m         batch_request,\n\u001b[1;32m     83\u001b[0m         response_type,\n\u001b[1;32m     84\u001b[0m         poll_interval\u001b[38;5;241m=\u001b[39mpoll_interval,\n\u001b[1;32m     85\u001b[0m         max_num_retries\u001b[38;5;241m=\u001b[39mmax_num_retries,\n\u001b[1;32m     86\u001b[0m     )\n\u001b[0;32m---> 88\u001b[0m batch_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_generate(\n\u001b[1;32m     89\u001b[0m     batch_request, response_type, poll_interval\n\u001b[1;32m     90\u001b[0m )\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch_result\n",
      "File \u001b[0;32m/workspaces/math_rag/infrastructure/inference/partials/partial_batch_llm.py:26\u001b[0m, in \u001b[0;36mPartialBatchLLM._batch_generate\u001b[0;34m(self, batch_request, response_type, poll_interval)\u001b[0m\n\u001b[1;32m     23\u001b[0m batch_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_generate_init(batch_request)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 26\u001b[0m     batch_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_generate_result(batch_id, response_type)\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m batch_result\n",
      "File \u001b[0;32m/workspaces/math_rag/infrastructure/inference/huggingface/huggingface_batch_llm.py:169\u001b[0m, in \u001b[0;36mHuggingFaceBatchLLM.batch_generate_result\u001b[0;34m(self, batch_id, response_type)\u001b[0m\n\u001b[1;32m    166\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremote_project_root \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput.jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    168\u001b[0m input_file_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msftp_client\u001b[38;5;241m.\u001b[39mdownload(input_path, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 169\u001b[0m output_file_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msftp_client\u001b[38;5;241m.\u001b[39mdownload(output_path, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    171\u001b[0m input_stream \u001b[38;5;241m=\u001b[39m FileStreamReaderUtil\u001b[38;5;241m.\u001b[39mread_jsonl(input_file_stream)\n\u001b[1;32m    172\u001b[0m output_stream \u001b[38;5;241m=\u001b[39m FileStreamReaderUtil\u001b[38;5;241m.\u001b[39mread_jsonl(output_file_stream)\n",
      "File \u001b[0;32m/workspaces/math_rag/infrastructure/clients/sftp_client.py:64\u001b[0m, in \u001b[0;36mSFTPClient.download\u001b[0;34m(self, source, target)\u001b[0m\n\u001b[1;32m     62\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m stack\u001b[38;5;241m.\u001b[39menter_async_context(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssh_client\u001b[38;5;241m.\u001b[39mconnect())\n\u001b[1;32m     63\u001b[0m sftp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m stack\u001b[38;5;241m.\u001b[39menter_async_context(conn\u001b[38;5;241m.\u001b[39mstart_sftp_client())\n\u001b[0;32m---> 64\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m stack\u001b[38;5;241m.\u001b[39menter_async_context(sftp\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mstr\u001b[39m(source), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m FileStreamWriterUtil\u001b[38;5;241m.\u001b[39mwrite_sftp(file, target)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/contextlib.py:659\u001b[0m, in \u001b[0;36mAsyncExitStack.enter_async_context\u001b[0;34m(self, cm)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object does \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    657\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot support the asynchronous context manager protocol\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    658\u001b[0m                    ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 659\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m _enter(cm)\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_push_async_cm_exit(cm, _exit)\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/workspaces/.venv/lib/python3.12/site-packages/asyncssh/misc.py:362\u001b[0m, in \u001b[0;36m_ACMWrapper.__aenter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__aenter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _ACM:\n\u001b[0;32m--> 362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coro_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coro\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coro_result\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__aenter__\u001b[39m()\n",
      "File \u001b[0;32m/workspaces/.venv/lib/python3.12/site-packages/asyncssh/sftp.py:4727\u001b[0m, in \u001b[0;36mSFTPClient.open\u001b[0;34m(self, path, pflags_or_mode, attrs, encoding, errors, block_size, max_requests)\u001b[0m\n\u001b[1;32m   4724\u001b[0m     pflags \u001b[38;5;241m=\u001b[39m pflags_or_mode\n\u001b[1;32m   4726\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_path(path)\n\u001b[0;32m-> 4727\u001b[0m handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handler\u001b[38;5;241m.\u001b[39mopen(path, pflags, attrs)\n\u001b[1;32m   4729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SFTPClientFile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handler, handle, \u001b[38;5;28mbool\u001b[39m(pflags \u001b[38;5;241m&\u001b[39m FXF_APPEND),\n\u001b[1;32m   4730\u001b[0m                       encoding, errors, block_size, max_requests)\n",
      "File \u001b[0;32m/workspaces/.venv/lib/python3.12/site-packages/asyncssh/sftp.py:2769\u001b[0m, in \u001b[0;36mSFTPClientHandler.open\u001b[0;34m(self, filename, pflags, attrs)\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2766\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug1(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSending open for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, mode 0x\u001b[39m\u001b[38;5;132;01m%02x\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   2767\u001b[0m                        filename, pflags, hide_empty(attrs))\n\u001b[0;32m-> 2769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m   2770\u001b[0m         FXP_OPEN, String(filename), UInt32(pflags),\n\u001b[1;32m   2771\u001b[0m         attrs\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_version)))\n",
      "File \u001b[0;32m/workspaces/.venv/lib/python3.12/site-packages/asyncssh/sftp.py:2561\u001b[0m, in \u001b[0;36mSFTPClientHandler._make_request\u001b[0;34m(self, pkttype, *args)\u001b[0m\n\u001b[1;32m   2558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resptype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (FXP_STATUS, return_type):\n\u001b[1;32m   2559\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SFTPBadMessage(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnexpected response type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresptype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2561\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_packet_handlers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mresptype\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m return_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/workspaces/.venv/lib/python3.12/site-packages/asyncssh/sftp.py:2577\u001b[0m, in \u001b[0;36mSFTPClientHandler._process_status\u001b[0;34m(self, packet)\u001b[0m\n\u001b[1;32m   2574\u001b[0m     packet\u001b[38;5;241m.\u001b[39mcheck_end()\n\u001b[1;32m   2576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc:\n\u001b[0;32m-> 2577\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m   2578\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2579\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug1(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReceived OK\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mSFTPNoSuchFile\u001b[0m: No such file"
     ]
    }
   ],
   "source": [
    "res = await llm.batch_generate(\n",
    "    batch_request=batch_request,\n",
    "    response_type=SomeOutput,\n",
    "    poll_interval=3 * 60,\n",
    "    max_num_retries=0,\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run assets/hpc/hf/tgi/tgi.py   # TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
